<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Machine Learning - AikenH Blogs</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Aiken Hong"><meta name="msapplication-TileImage" content="/img/pokemon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aiken Hong"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="tech, AI, code, Life"><meta property="og:type" content="blog"><meta property="og:title" content="AikenH Blogs"><meta property="og:url" content="http://aikenh.cn/"><meta property="og:site_name" content="AikenH Blogs"><meta property="og:description" content="tech, AI, code, Life"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://aikenh.cn/img/og_image.png"><meta property="article:author" content="AikenH"><meta property="article:tag" content="AikenH,Aiken,blog,Blog"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://aikenh.cn/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://aikenh.cn"},"headline":"AikenH Blogs","image":["http://aikenh.cn/img/og_image.png"],"author":{"@type":"Person","name":"AikenH"},"publisher":{"@type":"Organization","name":"AikenH Blogs","logo":{"@type":"ImageObject","url":{"text":"Aiken's Blog"}}},"description":"tech, AI, code, Life"}</script><link rel="icon" href="/img/pokemon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css" title="default"><link rel="alternate stylesheet" href="/css/cyberpunk.css" title="cyberpunk"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="AikenH Blogs" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aiken&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-lightbulb" id="night-icon"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Machine Learning</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/YOLOv4/"><img class="fill" src="/img/header_img/lml_bg33.jpg" alt="YOLOv4"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/YOLOv4/"><i class="fas fa-angle-double-right"></i>YOLOv4</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-03T05:16:40.000Z" title="2021-10-03T05:16:40.000Z">2021-10-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">11 minutes read (About 1638 words)</span></div></div><div class="content"><p>@AikenHong 20200726</p>
<p>基于YOLO v4 掌握一些CV方面训练的<strong>Trick</strong>，同时针对Typora的使用进行一个熟悉掌握。<a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">GITHUB CODE</a></p>
<p>一些相关的参考资料</p>
<p>⚡️<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/150127712">https://zhuanlan.zhihu.com/p/150127712</a></p>
<p>⚡ <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650785604&amp;idx=1&amp;sn=46bd186e5291deded9f6ec1ae6a22649&amp;chksm=871a033ab06d8a2cff370a06e9e88f578a6c16a70231778ae2f997a8b30e347c6e746db10759&amp;mpshare=1&amp;scene=1&amp;srcid=0429kHitmMCPeF2JGN1XCzik&amp;sharer_sharetime=1588144165276&amp;sharer_shareid=484a4a951d2ad320314b6b56ee9a0ba8&amp;key=c53866ae67b2b8c4b46c89671357025dcdb6b895d1ebde603135230e484682a3552d924bf6126ecf72cb98361e1171f0f0381bee5bd456520dd201034c33ec48272d62ae73345cc914c2db9c6e943a10&amp;ascene=1&amp;uin=NTkyNDg4NjQw&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=ASfZUAGjes1A%2BJpXS1yNmT0%3D&amp;pass_ticket=GB56ClnZIrs5ENfLSAh4yF9tj54n041FM39bTg38LQuW%2FKDyBPyfqKLD8SDIZgE%2F">机器之心YOLOv4</a></p>
<p>⚡️<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/390191723/answer/1177584901">https://www.zhihu.com/question/390191723/answer/1177584901</a></p>
<p><strong>本文中一些其他的收获</strong></p>
<p>•  其他可替代的Object Detection的SOTA算法有哪些</p>
<p>•  BoS，BoF方法</p>
<p>•  简直是一个Tricks的综述</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些<strong>通用的**</strong>Trick<strong>**的组合</strong>尝试，包括</p>
<p>•  加权残差连接（WRC）</p>
<p>•  Cross-Stage-Partial-connection，CSP</p>
<p>•  Cross mini-Batch Normalization，CmBN</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/YOLOv4/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/OW-OD/"><img class="fill" src="/img/header_img/lml_bg16.jpg" alt="OW Object Detector"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/OW-OD/"><i class="fas fa-angle-double-right"></i>OW Object Detector</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-28T05:44:20.000Z" title="2021-09-28T05:44:20.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:18:24.000Z" title="2023/10/31 08:18:24">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 875 words)</span></div></div><div class="content"><p>@Aiken 2021 </p>
<p>框架撞车系列，主要看看这一篇论文中怎么解决如下的问题👇，并从中借鉴和优化的我框架设计</p>
<h2 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><strong>模型实现的主要的两个TASK：</strong></p>
<ol>
<li>Open Set Learning ： 在没有明确监督的时候，将尚未引入的目标类别识别为未知</li>
<li>Incremental Learning：类别增量学习</li>
</ol>
<p><strong>实现这两个问题的主要思路：</strong></p>
<ul>
<li><strong>自动标注</strong>：借鉴RPN的class-agnostic，以及检测和分类的显著性指标的差异，找到并自动标注NewClass</li>
<li><strong>对比聚类：</strong>使用prototype feature来进行聚类，同时计算Distance损失<br>it seems like contain a unknown prototype.</li>
<li><strong>energy based：</strong>亥姆霍兹自由能公式？</li>
</ul>
<p><img src="https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210412171723896.png" alt="image-20210412171723896"></p>
<h3 id="ENERGY-BASED"><a href="#ENERGY-BASED" class="headerlink" title="ENERGY BASED"></a><strong>ENERGY BASED</strong></h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV, </a><a class="link-muted" rel="tag" href="/tags/Open-World-Learning/">Open World Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/OW-OD/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Attention/"><img class="fill" src="/img/header_img/lml_bg5.jpg" alt="Attention Mechanism"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Attention/"><i class="fas fa-angle-double-right"></i>Attention Mechanism</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-27T21:34:22.000Z" title="2021-09-27T21:34:22.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">18 minutes read (About 2748 words)</span></div></div><div class="content"><p>@Aiken 2020.9.16</p>
<p>对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Attention/">Attention </a></div><a class="article-more button is-small is-size-7" href="/cn/Attention/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/EfficientNet/"><img class="fill" src="/img/header_img/lml_bg15.jpg" alt="EfficientNet"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/EfficientNet/"><i class="fas fa-angle-double-right"></i>EfficientNet</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-27T21:34:22.000Z" title="2021-09-27T21:34:22.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 685 words)</span></div></div><div class="content"><p>Tags: Paper<br>URL1: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.11946.pdf">https://arxiv.org/pdf/1905.11946.pdf</a><br>URL2: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.00298.pdf">https://arxiv.org/pdf/2104.00298.pdf</a></p>
<p>提出了一种模型缩放策略，如何更高效的平衡网络的深度、宽度、和图片分辨率<br>**1. Efficient Net: Rethinking Model Scaling for Convolutional Neural Networks</p>
<ol>
<li>EfficientNetV2: Smaller Models and Faster Training**</li>
</ol>
<hr>
<p>@Aiken H 2021 find detail to code his </p>
<h1 id="Efficient-Net-V1"><a href="#Efficient-Net-V1" class="headerlink" title="Efficient Net V1"></a>Efficient Net V1</h1><p>除了提出了缩放策略以外，还使用神经架构搜索还建立了一个新的baseline network，得到了一系列模型。</p>
<p>平衡网络宽度、深度、分辨率至关重要，这种平衡可以通过简单的恒定比率缩放维度来实现，于是我们<strong>提出了一种简单有效的复合缩放</strong>方法。</p>
<p><img src="https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210610180603496.png" alt="https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210610180603496.png"></p>
<p>复合缩放的物理意义：输入图像更大的话就需要更多层来增加感受野和更多通道，从而能在更大的图像上捕获更多细粒度的图案，而宽度和深度（对于表达能力来说很重要）之间也存在着一定的关系，“我们”是第一个对此进行了建模的。</p>
<p>从各个维度单独的进行缩放能发现都存在着增益瓶颈，如何去得到这么一个合适的等比缩放增益<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/EfficientNet/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/RL-DouZero/"><img class="fill" src="/img/header_img/lml_bg23.jpg" alt="RL-DouZero"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/RL-DouZero/"><i class="fas fa-angle-double-right"></i>RL-DouZero</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-07-06T05:51:48.000Z" title="2021-07-06T05:51:48.000Z">2021-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">9 minutes read (About 1337 words)</span></div></div><div class="content"><p>Desc: GAME, RL<br>Finished?: Yes<br>Tags: Paper<br>URL1: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.06135">https://arxiv.org/abs/2106.06135</a><br>URL2: <a target="_blank" rel="noopener" href="https://github.com/kwai/DouZero">https://github.com/kwai/DouZero</a><br>URL3: <a target="_blank" rel="noopener" href="https://github.com/datamllab/rlcard-showdown）">https://github.com/datamllab/rlcard-showdown）</a></p>
<p>使用蒙特卡洛方法进行自我对弈不断更新预测模型的方法，这实际上也是普通人对于强化学习如何在self-play中实现自我更新的最基础的想法把：<br>自我对弈（记录动作序列）- 用最终的胜负（价值）更新网络。</p>
<h2 id="算法的设计和思路"><a href="#算法的设计和思路" class="headerlink" title="算法的设计和思路"></a>算法的设计和思路</h2><p>算法的目标是学习一个价值网路。网络的输入是当前状态和一个动作，输出是在当前状态做这个动作的期望收益（比如胜率）。简单来说，价值网络在每一步计算出哪种牌型赢的概率最大，然后选择最有可能赢的牌型。蒙特卡罗方法不断重复以下步骤来优化价值网络：</p>
<ul>
<li>用价值网络生成一场对局</li>
<li>记录下该对局中所有的状态、动作和最后的收益（胜率）</li>
<li>将每一对状态和动作作为网络输入，收益作为网络输出，用梯度下降对价值网络进行一次更新</li>
</ul>
<p>其实，所谓的蒙特卡罗方法就是一种随机模拟，即通过不断的重复实验来估计真实价值。</p>
<p>如下图所示，斗零采用一个价值神经网络，其输入是状态和动作，输出是价值。首先，过去的出牌用 LSTM 神经网络进行编码。然后 LSTM 的输出以及其他的表征被送入了 6 层全连接网络，最后输出价值。<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Reinforcement-learning/">Reinforcement learning </a></div><a class="article-more button is-small is-size-7" href="/cn/RL-DouZero/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Pooling/"><img class="fill" src="/img/header_img/lml_bg14.jpg" alt="Pooling"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Pooling/"><i class="fas fa-angle-double-right"></i>Pooling</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-06-23T05:48:56.000Z" title="2021-06-23T05:48:56.000Z">2021-06-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">17 minutes read (About 2493 words)</span></div></div><div class="content"><h1 id="DownSampling：Pooling的全面调研"><a href="#DownSampling：Pooling的全面调研" class="headerlink" title="DownSampling：Pooling的全面调研"></a>DownSampling：Pooling的全面调研</h1><p>@Aiken 2021 笔记摘录：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341820742">深度神经网络中的池化方法：全面调研（1989-2020） - 知乎</a> ；<a target="_blank" rel="noopener" href="https://www.sohu.com/a/442710521_823210">相同论文的简单中文Version</a></p>
<p>16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…</p>
<p>来自 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341820742">https://zhuanlan.zhihu.com/p/341820742</a></p>
<p>原文：《Pooling Methods in Deep Neural Networks, a Review》</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112216409">整合2</a></p>
<h2 id="池化的根本目的（Motivation）"><a href="#池化的根本目的（Motivation）" class="headerlink" title="池化的根本目的（Motivation）"></a>池化的根本目的（Motivation）</h2><p>卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。</p>
<p>池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层<strong>极大地减小了输入的空间尺寸</strong>。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。</p>
<ul>
<li>池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。</li>
<li>增大感受野；</li>
<li>降低优化难度和参数数目，</li>
</ul>
<p>理想的池化方法应仅提取有用的信息，并丢弃无关的细节。</p>
<p><strong>特征不变性、特征降维、在一定程度上防止过拟合，更方便优化</strong></p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Pooling/">Pooling </a></div><a class="article-more button is-small is-size-7" href="/cn/Pooling/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/OW-openmix/"><img class="fill" src="/img/header_img/lml_bg36.jpg" alt="OW-openmix"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/OW-openmix/"><i class="fas fa-angle-double-right"></i>OW-openmix</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-06-23T05:45:50.000Z" title="2021-06-23T05:45:50.000Z">2021-06-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 836 words)</span></div></div><div class="content"><p>@Aiken 2021 究极万恶的撞车论文</p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><strong>Motivation</strong> ：Tackle the problem of 发现无标注数据中与给定（已知）类别不相交的新类。</p>
<p><strong>Related Research：</strong></p>
<p>现有的方法通常1. 使用标记数据对模型进行预训练； 2. 无监督聚类在未标记的数据中识别新的类</p>
<blockquote>
<p>作者认为label带来的essential knowledge在第二步中没有被充分学习利用到，这样模型就只能从第一步的现成知识中获益，而不能利用标记数据和未标记数据之间的潜在关系</p>
</blockquote></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/OW-openmix/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/RL-Reward_is_enough/"><img class="fill" src="/img/header_img/lml_bg32.jpg" alt="Reward is Enough"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/RL-Reward_is_enough/"><i class="fas fa-angle-double-right"></i>Reward is Enough</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-06-06T05:53:36.000Z" title="2021-06-06T05:53:36.000Z">2021-06-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">3 minutes read (About 390 words)</span></div></div><div class="content"><p>Desc: RL<br>Finished?: Yes<br>Tags: Paper</p>
<p>通用人工智能，是否能通过强化学习的奖励机制就实现</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/XTNyLjZ9KfdtHY4Omb9_4w">实现AGI，强化学习就够了？Sutton、Silver师徒联手：奖励机制足够实现各种目标</a></p>
<h2 id="对reward构建AGI的可行性的分析和探讨"><a href="#对reward构建AGI的可行性的分析和探讨" class="headerlink" title="对reward构建AGI的可行性的分析和探讨"></a>对reward构建AGI的可行性的分析和探讨</h2><p>这篇文章实际上没有给出一个很好的方案通过reward来实现各种AGI的设计，但是给出了在每一种场景下的AGI的reward设计的设想把。和对用reward进行设计的可行性分析。<br>同时分析了：感知、社交、语言、泛化、模仿，这几个方面</p>
<blockquote>
<p>类似地，如果人工智能体的经验流足够丰富，那么单一目标（例如电池寿命或生存）可能隐含地需要实现同样广泛的子目标的能力，因此奖励最大化应该足以产生一种通用人工智能。</p>
</blockquote>
<p>这不久回到了最基础的问题，没有这种长线以及大量数据交互以及全面场景的经验流，来支撑这样一个AGI的学习，所以这不也是在现阶段上纸上谈兵嘛？</p>
<p>对这篇论文我的总结是，我不推荐详细阅读，我觉得收益有限，太理想化，其实和强化学习本身的假设也没有太多新东西，我们可以假设强化学习能带来一个AGI，但是对应的约束和限制确实是有点多了。</p>
</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Reinforcement-learning/">Reinforcement learning </a></div></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/RL-MobaAI_Tencent/"><img class="fill" src="/img/header_img/lml_bg21.jpg" alt="RL-MobaAI"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/RL-MobaAI_Tencent/"><i class="fas fa-angle-double-right"></i>RL-MobaAI</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-05-30T05:52:42.000Z" title="2021-05-30T05:52:42.000Z">2021-05-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">10 minutes read (About 1426 words)</span></div></div><div class="content"><p>Created by: Aiken H<br>Desc: GAME, RL<br>Finished?: Yes<br>Tags: Paper</p>
<p>《Master Complex Control in MOBA Games with Deep Reinforcement Learning》 论文阅读笔记</p>
<p>@Aiken H 2021.06</p>
<h2 id="Introduction-and-Related-Research"><a href="#Introduction-and-Related-Research" class="headerlink" title="Introduction and Related Research."></a>Introduction and Related Research.</h2><p>MOBA游戏的复杂度和状态空间都远比以前的围棋之类的运动更大，所以难度会更大一些</p>
<p>早一些的游戏ai使用的是（2015） Deep Q-Network  通过 supervised learning and self-play 结合的训练策略在围棋上击败了专业人类，而最近更多的使用了DRL（Deep Reinforcement Learning）的方法在近几年被进一步的应用。</p>
<h3 id="Neural-Network-Architecture-Include"><a href="#Neural-Network-Architecture-Include" class="headerlink" title="Neural Network Architecture Include"></a><strong>Neural Network Architecture Include</strong></h3><h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a><strong>Contributions</strong></h3><ul>
<li>the <strong>encoding</strong> of <strong>Multi-modal inputs 多模态输入</strong></li>
<li>the <strong>decoupling</strong> of inter-correlations in controls <strong>控制内关联解码</strong></li>
<li>exploration <strong>pruning</strong> mechanism  <strong>剪枝设置</strong></li>
<li><strong>Action mask</strong> for efficient exploration ❓<strong>效率</strong></li>
<li>attack <strong>attention</strong>(for target selection) <strong>Attention机制做目标选择</strong></li>
<li><strong>LSTM</strong> for learning skill combos <strong>LSTM 机制做技能释放和链接</strong></li>
<li><strong>Optimize</strong> by multi-label proximal policy algorithm(<strong>improved PPO</strong>)<ul>
<li>dual-clip PPO 帮助训练的收敛</li>
</ul>
</li>
</ul>
<hr></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Reinforcement-learning/">Reinforcement learning </a></div><a class="article-more button is-small is-size-7" href="/cn/RL-MobaAI_Tencent/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/RL-C1/"><img class="fill" src="/img/header_img/lml_bg42.jpg" alt="RL Notebook 01"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/RL-C1/"><i class="fas fa-angle-double-right"></i>RL Notebook 01</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-05-23T05:50:06.000Z" title="2021-05-23T05:50:06.000Z">2021-05-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">42 minutes read (About 6274 words)</span></div></div><div class="content"><p>Created by: Aiken H<br>Detail: survey<br>Finished?: No<br>Tags: Paper<br>URL1: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/category/1254674.html">https://www.cnblogs.com/pinard/category/1254674.html</a><br>URL2: <a target="_blank" rel="noopener" href="https://github.com/ljpzzz/machinelearning">https://github.com/ljpzzz/machinelearning</a><br>URL3: <a target="_blank" rel="noopener" href="https://datawhalechina.github.io/easy-rl/#/">https://datawhalechina.github.io/easy-rl/#/</a></p>
<h1 id="Chapter1-模型基础"><a href="#Chapter1-模型基础" class="headerlink" title="Chapter1 模型基础"></a>Chapter1 模型基础</h1><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/9385570.html">强化学习（一）模型基础</a></p>
<p>强化学习是介于监督和无监督学习之间的，强化学习没有输出值，但是有<strong>reward：</strong> 同时这个reward是事后给出的，而不是及时回馈的。而无监督学习是只有数据特征，同时数据之间是独立的，没有前后依赖的关系。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911210000.png" alt="https://images2018.cnblogs.com/blog/1042406/201807/1042406-20180729163058011-290427357.png"></p>
<h2 id="Theory理论基础"><a href="#Theory理论基础" class="headerlink" title="Theory理论基础"></a>Theory理论基础</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Reinforcement-learning/">Reinforcement learning </a></div><a class="article-more button is-small is-size-7" href="/cn/RL-C1/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IntView_%E9%9D%A2%E8%AF%95%E8%A1%A5%E5%85%85/"><img class="fill" src="/img/header_img/lml_bg23.jpg" alt="经典深度学习与机器学习算法"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IntView_%E9%9D%A2%E8%AF%95%E8%A1%A5%E5%85%85/"><i class="fas fa-angle-double-right"></i>经典深度学习与机器学习算法</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-04-22T17:43:43.000Z" title="2021-04-22T17:43:43.000Z">2021-04-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:10:03.000Z" title="2023/10/31 08:10:03">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">an hour read (About 11463 words)</span></div></div><div class="content">Here's something encrypted, password is required to continue reading.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Job/">Job </a></div><a class="article-more button is-small is-size-7" href="/cn/IntView_%E9%9D%A2%E8%AF%95%E8%A1%A5%E5%85%85/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Involution/"><img class="fill" src="/img/header_img/lml_bg21.jpg" alt="Involution"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Involution/"><i class="fas fa-angle-double-right"></i>Involution</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-04-08T05:12:15.000Z" title="2021-04-08T05:12:15.000Z">2021-04-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 894 words)</span></div></div><div class="content"><p>@Aiken 2021-4-8</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/UmumqhZW7Aqk6s8X1Aj7aA">Ariticle </a>；<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.06255">Paper</a>；<a target="_blank" rel="noopener" href="https://github.com/d-li14/involution">:star:Code；</a> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/357408252">ZHIHU</a></p>
<h2 id="Intro-引子"><a href="#Intro-引子" class="headerlink" title="Intro 引子"></a>Intro 引子</h2><p>提出了一种新的神经网络算子（operator或op）称为involution，它比convolution更轻量更高效，形式上比self-attention更加简洁，可以用在各种视觉任务的模型上取得精度和效率的双重提升。</p>
<p>通过involution的结构设计，我们能够以统一的视角来理解经典的卷积操作和近来流行的自注意力操作。</p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>将传统Convolution Kernel 的两个基本特性：</p>
<ul>
<li><strong>空间不变性：</strong>在同个通道的HW上共享3*3的卷积系数，参数共享；</li>
<li><strong>通道特异性：</strong>在每个通道上有特异的卷积核，最终使用1*1 like的方式来进行通道间的整合</li>
</ul>
<p>反对称的修改成：</p>
<ul>
<li><strong>空间特异性：</strong> 对每个Feature有对应size  $H·W·K·K·G | G&lt;&lt;C$  的kernel，特异性的对不同图像的不同部分进行处理<ul>
<li>G表示Involution操作的分组数，如果需要下采样，就需要接步长为2的平均池化层，最终可以得到，实际上是一个分组卷积的方式，也就是说，我们K个一组的共享一个Kernel。用G去切分C，最终组合起来</li>
</ul>
</li>
<li><strong>通道不变性：</strong>对每个通道之间共享这样的kernel，然后做简单的线性整合，对每个不同的channel有相同的处理方式。</li>
</ul>
<p>传统的卷积基于邻域相关性的思想，同时旨在同一个channel中用单一的角度去分析特征，所以有空间不变性核通道特异性的这两个特征。</p>
<p>而Involution实际上更像是Self-Attention这种思路，通过Whole-Size的Kernel，执行一个特异性处理？</p>
<h2 id="要点分析"><a href="#要点分析" class="headerlink" title="要点分析"></a>要点分析</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/Involution/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/KnowledgeEvolution/"><img class="fill" src="/img/header_img/lml_bg36.jpg" alt="Knowledge Evolution"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/KnowledgeEvolution/"><i class="fas fa-angle-double-right"></i>Knowledge Evolution</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-04-06T21:34:22.000Z" title="2021-04-06T21:34:22.000Z">2021-04-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">7 minutes read (About 994 words)</span></div></div><div class="content"><h1 id="Knowledge-Evolution-in-Neural-Networks"><a href="#Knowledge-Evolution-in-Neural-Networks" class="headerlink" title="Knowledge Evolution in Neural Networks"></a>Knowledge Evolution in Neural Networks</h1><p>@Aiken 2021.4.7  </p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ZdHhdTrHmdcBF4DYf1HXPQ">Article：只能当成OverView，技术细节写的很差</a>；Mendeley；</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ahmdtaha/knowledge_evolution">Code_PyTorch</a></p>
<h2 id="Intro引子"><a href="#Intro引子" class="headerlink" title="Intro引子"></a><strong>Intro引子</strong></h2><p><strong>Problem</strong>：如何在较小的数据集上训练神经网络，这到底是个小样本的方法还是个类别增量的方法？</p>
<p><strong>Motivation：</strong> 考虑生物“基因”进化的方式，有一部分是“祖传”，另一部分是“适应”，通过对“祖传”的假设的不断学习进化，得到一个新的模型。</p>
<blockquote>
<p>基因编码了从祖先到后代的遗传信息（知识），而基因传递将遗传信息从父母传递至其后代。虽然祖先并不一定具有更好的知识，但是遗传信息（知识）在几代人之间的发展将会促进后代更好的学习曲线。</p>
</blockquote>
<p><strong>Hypothesis：</strong> </p>
<ul>
<li>拟合假设$H^{origin}$：</li>
<li>重置假设：$H^{later}$</li>
</ul>
<p>TOBEUPDATE：将神经网络拆分成两个假设(子网络)：通过重新训练多代网络来进化$H^{origin}$ 中的知识，每一代都会扰乱$H^{later}$的内部权重来鼓励$H^{origin}$ 学习独立的表达形式。</p>
<blockquote>
<p>将深度神经网络的知识封装在一个名为拟合假设的子网络H中，将拟合假设的知识从<strong>父母网络</strong>传递至其后代，即下一代神经网络。并反复重复此过程，在后代网络中证明了其性能的显著提升：</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/AikenH/md-image/master/img/640" alt="图片" style="zoom:67%;" /></p>
<p><strong>Contribution</strong>：</p>
<p>提出了KELS（内核级卷积感知拆分），为CNN量身定做。虽然增加了训练时间，但是大大降低了推理成本，也减轻了较小数据集中的过拟合问题。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/KnowledgeEvolution/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Facial_expression_and_Emotion/"><img class="fill" src="/img/header_img/lml_bg7.jpg" alt="Related Word of Emotion"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Facial_expression_and_Emotion/"><i class="fas fa-angle-double-right"></i>Related Word of Emotion</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2020-12-16T09:08:26.000Z" title="2020-12-16T09:08:26.000Z">2020-12-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">a minute read (About 180 words)</span></div></div><div class="content"><h2 id="疑似"><a href="#疑似" class="headerlink" title="疑似"></a>疑似</h2><ol>
<li><p>M. Suwa, N. Sugie and K. Fujimora, “A Preliminary Note on Pattern Recognition of Human Emotional Expression”, <em>Proc. Int’l Joint Conf. Pattern Recognition</em>, pp. 408-410, 1978.</p>
</li>
<li><p>K. Scherer and P. Ekman, <em>Handbook of Methods in Nonverbal Behavior Research.</em>, 1982.</p>
</li>
<li><p>J.M. Carroll and J. Russell, “Facial Expression in Hollywood’s Portrayal of Emotion”, <em>J. Personality and Social Psychology</em>, vol. 72, pp. 164-176, 1997.</p>
</li>
<li><p>Standardization and Assessment of College Students’ Facial Expression of Emotion.</p>
<p>好像是评估表情标注的，</p>
</li>
<li><p>Universals and cultural differences in the judgments of facial expressions of emotion<br>不同文化下的表情对应情感的认知</p>
</li>
<li><p>Classifying Emotion based on Facial Expression Analysis using Gabor Filter: A Basis for Adaptive Effective Teaching Strategy </p>
</li>
</ol>
<h2 id="确信"><a href="#确信" class="headerlink" title="确信"></a>确信</h2><ol>
<li><p><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/0-387-27257-7_12">Facial Expression Analysis</a><br>这篇的introduction里面有好几篇</p>
</li>
<li><p>Ekman P. Facial expression and emotion[J]. American psychologist, 1993, 48(4): 384.</p>
</li>
<li><p>Keltner D, Ekman P, Gonzaga G C, et al. Facial expression of emotion[J]. 2003.</p>
<p>上面这两篇的引用里应该能找到特别多</p>
</li>
<li><p>Xu R, Chen J, Han J, et al. Towards emotion-sensitive learning cognitive state analysis of big data in education: deep learning-based facial expression analysis using ordinal information[J]. Computing, 2019: 1-16.</p>
</li>
</ol></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Emotion/">Emotion </a></div><a class="article-more button is-small is-size-7" href="/cn/Facial_expression_and_Emotion/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/GANs/"><img class="fill" src="/img/header_img/lml_bg41.jpg" alt="GANs 01"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/GANs/"><i class="fas fa-angle-double-right"></i>GANs 01</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2020-10-18T23:47:36.000Z" title="2020-10-18T23:47:36.000Z">2020-10-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">7 minutes read (About 1014 words)</span></div></div><div class="content"><h1 id="fGAN-对GAN理论的深度理解"><a href="#fGAN-对GAN理论的深度理解" class="headerlink" title="fGAN 对GAN理论的深度理解"></a>fGAN 对GAN理论的深度理解</h1><p>@Aiken 2021 onenote部分的拓展编写，到时候拷过去，整合在一起。</p>
<p>fGAN: 不只是JS-Div散度，我们可以<strong>将所有的散度都应用到GANs的框架</strong>中。该部分的阅读是对GAN的基本理论最重要的文章之一。</p>
<h2 id="基本理论体系和推演"><a href="#基本理论体系和推演" class="headerlink" title="基本理论体系和推演"></a>基本理论体系和推演</h2><p>首先给出fGAN中提出的基本理论：可以将所有的Div放入GANs的框架中，来做那个核心的关键演化判别指标：</p>
<script type="math/tex; mode=display">
D_{f}(P||Q) = \int_xq(x)f(\frac{p(x)}{q(x)}dx)</script><p>上述公式将衡量P和Q两个分布之间的差距，公式中的$f$可以是很多不同的版本，但是要求满足如下的两个条件：</p>
<ol>
<li>是一个凸函数；$f(\frac{(x1+x2)}{2})\leq \frac{[f(x1)+f(x2)]}{2}$，需要注意国内外的凹凸相反</li>
<li>$f(1)=0$。</li>
</ol>
<p>而我们知道$q(x)$是概率密度分布函数，实际上可以看成凸函数性质的推广，所以我们可以证得：</p>
<script type="math/tex; mode=display">
D_{f}(P||Q) = \int_xq(x)f(\frac{p(x)}{q(x)}dx) \geq
f(\int q(x) \frac{p(x)}{q(x)} dx) = f(1) = 0</script><p>显然当我们取得合适的f，KL（$f(x) = xlog(x)$）; ReverseKL($-log(x)$)；chi square ($f(x) = (x-1)^2$)；</p>
<h3 id="Fenchel-Conjugate共轭"><a href="#Fenchel-Conjugate共轭" class="headerlink" title="Fenchel Conjugate共轭"></a>Fenchel Conjugate共轭</h3><p>补充Fenchel共轭的知识来对后续的fGAN推导进行补充，定理内容如下：<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/GAN/">GAN </a></div><a class="article-more button is-small is-size-7" href="/cn/GANs/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Hyper_Resolution/"><img class="fill" src="/img/header_img/lml_bg5.jpg" alt="Hyper-Resolution"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Hyper_Resolution/"><i class="fas fa-angle-double-right"></i>Hyper-Resolution</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2020-03-06T06:55:02.000Z" title="2020-03-06T06:55:02.000Z">2020-03-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">4 minutes read (About 597 words)</span></div></div><div class="content"><p>说明：重点针对<strong>超分辨率</strong>技术  </p>
<p>备注：<br>超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波<br></p>
<h2 id="超分辨率在表情识别中的应用"><a href="#超分辨率在表情识别中的应用" class="headerlink" title="超分辨率在表情识别中的应用"></a>超分辨率在表情识别中的应用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">KEY WORDs ：<br><br>1. (&quot;super resolution&quot; OR &quot;image restore&quot;) AND (&quot;facial expression recognition&quot; OR &quot;emotion recognition&quot;)   <br>2. (&quot;super resolution&quot;) AND  (&quot;expression recognition&quot;)   <br></code></pre></td></tr></table></figure>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1709.03126.pdf">&lt; Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach &gt;</a></p>
<blockquote>
<ul>
<li>针对于低带宽传输的分辨率不足和比率低的应用场景  </li>
<li>基于facial expression recognition 的 emotion recognition</li>
<li>在解码器进行视频下采样的时候，<strong>联合SR和识别</strong>    </li>
</ul>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231219312974">&lt; Effective image super resolution via hierarchical convolutional neural network &gt;</a>  </p>
<blockquote>
<ul>
<li>通过层次卷积神经网络(HCNN)来实现有校的SR</li>
<li>在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能</li>
</ul>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-319-56687-0_13">&lt; Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images &gt;</a>  </p>
<blockquote>
<ul>
<li>有点擦边吧，就是基于超分辨率算法的多分辨率图像，对面部进行识别从而判断疼痛程度</li>
<li>也可能妹啥用，你可以考虑一下</li>
</ul>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0165168419304232">&lt; Low-resolution facial expression recognition: A filter learning perspective &gt;</a>  </p>
<blockquote>
<ul>
<li>摘要中没有明确的提到Super-Resolution，</li>
<li>但是感觉低分辨率这个问题前缀，可能和SR有关系来着</li>
</ul>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www-nlpir.nist.gov/projects/tvpubs/tv19.papers/pku-icst.pdf">&lt; PKU_ICST at TRECVID 2019: Instance Search Task &gt;</a>  </p>
<blockquote>
<ul>
<li>好像是什么比赛，过程中有一部分是面部表情检测</li>
<li>在识别之前采取了超分辨率的查询增强</li>
</ul>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-37734-2_43">&lt; Facial Expression Restoration Based on Improved Graph Convolutional Networks &gt;</a>  </p>
<blockquote>
<ul>
<li>针对分辨率低和部分遮挡的面部表情识别 </li>
<li>GAN IGCN RRMB 修复和超分辨率面部表情    </li>
</ul>
</blockquote>
</li>
</ol></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/HyperResolution/">HyperResolution </a></div><a class="article-more button is-small is-size-7" href="/cn/Hyper_Resolution/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/ImageCaptionRequirement/"><img class="fill" src="/img/header_img/lml_bg6.jpg" alt="Image Caption Dataset"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/ImageCaptionRequirement/"><i class="fas fa-angle-double-right"></i>Image Caption Dataset</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2020-01-13T18:13:25.000Z" title="2020-01-13T18:13:25.000Z">2020-01-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:09:04.000Z" title="2023/10/31 08:09:04">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/Dataset/">Dataset</a></span><span class="level-item">5 minutes read (About 810 words)</span></div></div><div class="content"><h2 id="Goals："><a href="#Goals：" class="headerlink" title="Goals："></a>Goals：</h2><p>1.数据量要求<br>2.标注的标准<br>3.标注的手段  </p>
<h2 id="Microsoft-COCO-Captions"><a href="#Microsoft-COCO-Captions" class="headerlink" title="Microsoft COCO Captions:"></a>Microsoft COCO Captions:</h2><p>使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。<br>“Each of our captions are also generated using human subjects on AMT.”</p>
<h3 id="一些其他信息：-Caption-Evaluation-Server"><a href="#一些其他信息：-Caption-Evaluation-Server" class="headerlink" title="一些其他信息：(Caption Evaluation Server):"></a>一些其他信息：(Caption Evaluation Server):</h3><p>好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。<br>文中（section 3）包含了几种不同评价方法的介绍：  </p>
<blockquote>
<p>BLEU<br>ROUGE<br>METEOR<br>CIDEr</p>
</blockquote>
<p>在进行Evaluation之前的 Tokenization and preprocessing中：<br>使用了工具来添加caption标记：</p>
<ul>
<li>Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1)  </li>
</ul>
<p>这个工具是模仿的是peen treebank3.   其参考文献和相关链接如下：  </p>
<blockquote>
<p>“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/P/P14/P14-5010">related-link</a>  </p>
</blockquote>
<h3 id="数据规模："><a href="#数据规模：" class="headerlink" title="数据规模："></a>数据规模：</h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Dataset/">Dataset, </a><a class="link-muted" rel="tag" href="/tags/Image-Caption/">Image Caption </a></div><a class="article-more button is-small is-size-7" href="/cn/ImageCaptionRequirement/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Emotion_dataset/"><img class="fill" src="/img/header_img/lml_bg20.jpg" alt="表情数据集"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Emotion_dataset/"><i class="fas fa-angle-double-right"></i>表情数据集</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2019-10-14T13:34:54.000Z" title="2019-10-14T13:34:54.000Z">2019-10-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/Dataset/">Dataset</a></span><span class="level-item">7 minutes read (About 1112 words)</span></div></div><div class="content"><p>根据这次需要搜集的表情的数据集，整理一下搜索数据集的网站和思路等</p>
<h2 id="PART1-“表情数据集”"><a href="#PART1-“表情数据集”" class="headerlink" title="PART1 “表情数据集”"></a>PART1 “表情数据集”</h2><p>下列是对数据搜集的要求： </p>
<ul>
<li>是否开源</li>
<li>图片的大小和数量</li>
<li>图片的采集方式</li>
</ul>
<p>eg：<strong>ck+</strong>  </p>
<p>==数据来源及对应的搜索结果如下：==</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://toolbox.google.com/datasetsearch">谷歌数据集搜索导航</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.kairos.com/blog/60-facial-recognition-databases">60个人脸识别的数据集汇总</a>  </li>
<li><a target="_blank" rel="noopener" href="http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm">cv方面的好几百个数据集汇总</a>  </li>
<li><a href="www.cvpapers.com/datasets.html">另一个cv方向的数据集汇总</a>   </li>
<li><a target="_blank" rel="noopener" href="https://github.com/ChanChiChoi/awesome-Face_Recognition">github-CV汇总帖</a></li>
</ul>
<ol>
<li><a target="_blank" rel="noopener" href="http://cbcsl.ece.ohio-state.edu/EmotionNetChallenge/index.html#overview">EmotioNet</a>   </li>
</ol>
<blockquote>
<p>好像是一个什么挑战赛的数据集要博士后或者相应教员才能申请使用<a target="_blank" rel="noopener" href="http://cbcsl.ece.ohio-state.edu/dbform_compound.html">申请页面</a><br>没有具体的用于表情识别的数据子集的信息（好像数据很多，但是不知道在哪下，除了那个博士后申请的）  </p>
</blockquote>
<ol>
<li><a target="_blank" rel="noopener" href="http://www.whdeng.cn/RAF/model1.html">RAF</a>  </li>
</ol>
<blockquote>
<p>real-world Affective Face<br><strong>数据量</strong>29672个图像，7种基本情绪，12种复合情绪，（包含种族年龄范围性别属性，5个准确定位和37个自动生成的定位）<br><strong>数据收集方式：</strong>来源网络，大小应该很杂 （由40个人独立标定）<br>email  </p>
</blockquote></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Dataset/">Dataset, </a><a class="link-muted" rel="tag" href="/tags/Emotion/">Emotion </a></div><a class="article-more button is-small is-size-7" href="/cn/Emotion_dataset/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/Machine-Learning/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/Machine-Learning/page/3/"> common.next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/Machine-Learning/">1</a></li><li><a class="pagination-link is-current" href="/categories/Machine-Learning/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/title.jpg" alt="AikenH"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">AikenH</p><p class="is-size-6 is-block">Future Full-Stack Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ShenZhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">161</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">48</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">104</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/AikenH" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="ZhiHu" href="https://www.zhihu.com/people/Aiken-h"><i class="fab fa-zhihu"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/1788200627"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Steam" href="https://steamcommunity.com/id/AikenH/"><i class="fab fa-steam"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/cn/TS1_%E5%A4%B4%E6%96%87%E4%BB%B6%E4%BA%92%E7%9B%B8%E5%8C%85%E5%90%AB/"><img src="/img/header_img/lml_bg0.jpg" alt="CPP_头文件互相包含"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-10-22T09:05:32.000Z">2024-10-22</time></p><p class="title"><a href="/cn/TS1_%E5%A4%B4%E6%96%87%E4%BB%B6%E4%BA%92%E7%9B%B8%E5%8C%85%E5%90%AB/">CPP_头文件互相包含</a></p><p class="categories"><a href="/categories/Langs/">Langs</a> / <a href="/categories/Langs/Cpp/">Cpp</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/LearnWeb21-JS06-%E5%BC%82%E6%AD%A5JS/"><img src="/img/header_img/lml_bg39.jpg" alt="LearnWeb21-JS06-异步JS"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-04-30T22:22:33.000Z">2024-05-01</time></p><p class="title"><a href="/cn/LearnWeb21-JS06-%E5%BC%82%E6%AD%A5JS/">LearnWeb21-JS06-异步JS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/LearnWeb20-JS05-JSON%E4%BD%BF%E7%94%A8/"><img src="/img/header_img/lml_bg1.jpg" alt="LearnWeb20-JS05-JSON使用"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-04-30T06:44:51.000Z">2024-04-30</time></p><p class="title"><a href="/cn/LearnWeb20-JS05-JSON%E4%BD%BF%E7%94%A8/">LearnWeb20-JS05-JSON使用</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/JS/">JS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/LearnWeb19-JS04-%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/"><img src="/img/header_img/lml_bg36.jpg" alt="LearnWeb19-JS04-类与对象"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-04-28T08:46:21.000Z">2024-04-28</time></p><p class="title"><a href="/cn/LearnWeb19-JS04-%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/">LearnWeb19-JS04-类与对象</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/JS/">JS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/LearnWeb18-JS03-%E4%BA%8B%E4%BB%B6/"><img src="/img/header_img/lml_bg37.jpg" alt="LearnWeb18-JS03-事件"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-04-17T01:31:23.000Z">2024-04-17</time></p><p class="title"><a href="/cn/LearnWeb18-JS03-%E4%BA%8B%E4%BB%B6/">LearnWeb18-JS03-事件</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/JS/">JS</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Acceleration/"><span class="tag">Acceleration</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention/"><span class="tag">Attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Augmentation/"><span class="tag">Augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Blog/"><span class="tag">Blog</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSS/"><span class="tag">CSS</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Clash/"><span class="tag">Clash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud/"><span class="tag">Cloud</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Colab/"><span class="tag">Colab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Configuration/"><span class="tag">Configuration</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cpp/"><span class="tag">Cpp</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Database/"><span class="tag">Database</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataset/"><span class="tag">Dataset</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dev/"><span class="tag">Dev</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Django/"><span class="tag">Django</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DualSystem/"><span class="tag">DualSystem</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Env/"><span class="tag">Env</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Game-Generate/"><span class="level-start"><span class="level-item">Game Generate</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Leetcode/"><span class="level-start"><span class="level-item">Leetcode</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Blog/"><span class="level-start"><span class="level-item">Blog</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Blog/Gitbook/"><span class="level-start"><span class="level-item">Gitbook</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Blog/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Dev/"><span class="level-start"><span class="level-item">Dev</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/Dev/Devops/"><span class="level-start"><span class="level-item">Devops</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/Raspberry-pie/"><span class="level-start"><span class="level-item">Raspberry-pie</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/SSH/"><span class="level-start"><span class="level-item">SSH</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Docker/Containers/"><span class="level-start"><span class="level-item">Containers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Editor/Obsidian/"><span class="level-start"><span class="level-item">Obsidian</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Editor/Vim/"><span class="level-start"><span class="level-item">Vim</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Editor/Vscode/"><span class="level-start"><span class="level-item">Vscode</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Frontend/"><span class="level-start"><span class="level-item">Frontend</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Frontend/Vue/"><span class="level-start"><span class="level-item">Vue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Github/"><span class="level-start"><span class="level-item">Github</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/"><span class="level-start"><span class="level-item">Langs</span></span><span class="level-end"><span class="level-item tag">19</span></span></a><ul><li><a class="level is-mobile" href="/categories/Langs/Bash/"><span class="level-start"><span class="level-item">Bash</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Cpp/"><span class="level-start"><span class="level-item">Cpp</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Markdown/"><span class="level-start"><span class="level-item">Markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Nodejs/"><span class="level-start"><span class="level-item">Nodejs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Life/"><span class="level-start"><span class="level-item">Life</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Life/Investment/"><span class="level-start"><span class="level-item">Investment</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MacOS/"><span class="level-start"><span class="level-item">MacOS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">48</span></span></a><ul><li><a class="level is-mobile" href="/categories/Machine-Learning/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/Dataset/"><span class="level-start"><span class="level-item">Dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/NAS/"><span class="level-start"><span class="level-item">NAS</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/NAS/NAT/"><span class="level-start"><span class="level-item">NAT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Photography/"><span class="level-start"><span class="level-item">Photography</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/HTML/"><span class="level-start"><span class="level-item">HTML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/JS/"><span class="level-start"><span class="level-item">JS</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/Windows/APPs/"><span class="level-start"><span class="level-item">APPs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/Dual-System/"><span class="level-start"><span class="level-item">Dual System</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/Powershell/"><span class="level-start"><span class="level-item">Powershell</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/WSL2/"><span class="level-start"><span class="level-item">WSL2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Aiken&#039;s Blog</a><p class="is-size-7"><span>&copy; 2024 AikenH</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_pv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span> and <span id="busuanzi_container2_site_uv"><span id="busuanzi_value_site_pv">0</span>&nbsp;visits</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>