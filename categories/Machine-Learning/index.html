<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Machine Learning - AikenH Blogs</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Aiken Hong"><meta name="msapplication-TileImage" content="/img/pokemon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aiken Hong"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Development Documentation"><meta property="og:type" content="blog"><meta property="og:title" content="AikenH Blogs"><meta property="og:url" content="http://aikenh.cn/"><meta property="og:site_name" content="AikenH Blogs"><meta property="og:description" content="Development Documentation"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://aikenh.cn/img/og_image.png"><meta property="article:author" content="AikenH"><meta property="article:tag" content="AikenH,Aiken,blog,Blog"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://aikenh.cn/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://aikenh.cn"},"headline":"AikenH Blogs","image":["http://aikenh.cn/img/og_image.png"],"author":{"@type":"Person","name":"AikenH"},"publisher":{"@type":"Organization","name":"AikenH Blogs","logo":{"@type":"ImageObject","url":{"text":"Aiken's Blog"}}},"description":"Development Documentation"}</script><link rel="icon" href="/img/pokemon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css" title="default"><link rel="alternate stylesheet" href="/css/cyberpunk.css" title="cyberpunk"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="AikenH Blogs" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aiken&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-lightbulb" id="night-icon"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Machine Learning</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/StableDIffusionTraining/"><img class="fill" src="/img/header_img/lml_bg39.jpg" alt="AIGC05 Stable Diffusion Model Training"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/StableDIffusionTraining/"><i class="fas fa-angle-double-right"></i>AIGC05 Stable Diffusion Model Training</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-05-06T15:43:41.000Z" title="2023-05-06T15:43:41.000Z">2023-05-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/AIGC/">AIGC</a></span><span class="level-item">23 minutes read (About 3421 words)</span></div></div><div class="content"><blockquote>
<p>该章节主要介绍 Stable-Diffusion 中模型的训练，考虑到硬件条件的限制，实际上这里介绍的训练，都是针对大模型的各种微调技术（Lora，Dreambooth，HyperNetwork, …），这里会以 LoRA 模型的训练为主。</p>
</blockquote>
<p>参考文献：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.gamelook.com.cn/2023/04/514936">AIGC教程：Stable Diffusion精进，如何训练特定画风LoRA模型？ | 游戏大观 | GameLook.com.cn</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wangiqngpei557/p/17301360.html">stable diffusion打造自己专属的LORA模型 - 王清培 - 博客园 (cnblogs.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kohya-ss/sd-scripts/blob/main/train_README-zh.md">sd-scripts/train_README-zh.md at main · kohya-ss/sd-scripts · GitHub</a></li>
</ul>
<h2 id="Train-LoRA"><a href="#Train-LoRA" class="headerlink" title="Train LoRA"></a>Train LoRA</h2><blockquote>
<p>LoRA 的优势就是其模型更小，且更加模块化；也就是说其的训练成本和要求都更低，同时使用代价小，可以作为某种风格插件或者角色插件来使用。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/blog/zh/lora">使用 LoRA 进行 Stable Diffusion 的高效参数微调 (huggingface.co)</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.09685">[2106.09685] LoRA: Low-Rank Adaptation of Large Language Models (arxiv.org)</a></li>
</ul>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/20230706171541.png" alt="image.png"></p>
<p>其中蓝色的是预训练好的源网络，而橙色的是新加的网络，通过控制 R 的宽度（文章主要论证了大模型的参数可能存在较低维度的秩，因此可以使用较小的 R 来对大模型的参数造成有效的影响），可以有效的减少需要训练的网络的 Size。</p>
<h3 id="事前准备"><a href="#事前准备" class="headerlink" title="事前准备"></a>事前准备</h3><blockquote>
<p>这里只介绍本地训练，训练也可以在 Colab Notebook 等在线训练集群中进行，这里就不进行介绍了</p>
</blockquote>
<ol>
<li>WebUI + 想训练的基础 SD 模型</li>
<li><code>.txt</code> 带说明的文本文件</li>
<li>Training Repo（<a target="_blank" rel="noopener" href="https://github.com/kohya-ss/sd-scripts">sd-script</a>、<a target="_blank" rel="noopener" href="https://github.com/Akegarasu/lora-scripts">lora-script</a>）</li>
<li>数据集准备（准备好训练图像）</li>
</ol>
<h3 id="训练包准备"><a href="#训练包准备" class="headerlink" title="训练包准备"></a>训练包准备</h3><p>这里我们使用 lora-script 来进行模型训练，lora-script 实际上是 sd-script 之外在包了一层，新增了一些可视化的功能和一些其他的脚本，让 sd-script 更加易用，它调用 sd 中的脚本来实现训练，但是封装了一些注释和整理，此外还支持的 tensorboard 可视化。</p>
<blockquote>
<p>sd-script 本身包含了训练 lora、dreambooth、text-embedding、UNet、Text Encoder、图像生成、模型转换等多种功能。lora-script 还是主要专注于 LoRA 训练</p>
</blockquote>
<p>查看 repo 也能知道 lora-script 中包含了 sd-script，所以我们部署的时候只需</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> --recurse-submodules https://github.com/Akegarasu/lora-scripts<br></code></pre></td></tr></table></figure>
<p>即可将需要的库安装下来，然后安装环境和相关以来只需要执行 <code>.\install.ps1</code> 即可（该脚本有 cn 版本，但是可能会出现问题），其会安装 sd-scripts 和 lora-scripts 需要的库。具体的可以参考相关 repo（sd-script 详细说明，lora-script 有简化版说明）。</p>
<blockquote>
<p>安装的时候可能会出现虚拟环境未激活的问题，我们可以提前在改目录执行一次 python -m venv venv 一次即可。</p>
</blockquote>
<p>Finish.<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/AI/">AI </a></div><a class="article-more button is-small is-size-7" href="/cn/StableDIffusionTraining/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/StableDiffusionPrompt/"><img class="fill" src="/img/header_img/lml_bg29.jpg" alt="AIGC04 Stable Diffusion Write Prompt Better"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/StableDiffusionPrompt/"><i class="fas fa-angle-double-right"></i>AIGC04 Stable Diffusion Write Prompt Better</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-04-26T13:22:38.000Z" title="2023-04-26T13:22:38.000Z">2023-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/AIGC/">AIGC</a></span><span class="level-item">9 minutes read (About 1386 words)</span></div></div><div class="content"><blockquote>
<p>该章节主要包括 Promot 生成和部分工作流的分析，旨在了解如何写出更好的关键词，如何生成更好的图片，当我们不知道怎么描述的时候也可以将该工作交给 ChatGPT，让其为我们攥写一般基础的提示词</p>
</blockquote>
<h2 id="Prompt-编写范式"><a href="#Prompt-编写范式" class="headerlink" title="Prompt 编写范式"></a>Prompt 编写范式</h2><p>参考资料：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/619247417?utm_id=0">【Stable Diffusion】Prompt</a></p>
<p>通常编写可以遵照以下的类别进行组织，主要有 <code>&lt;质量控制&gt; + &lt;前置&gt; + &lt;主体&gt; + &lt;场景词&gt;</code> 几类，其中分别包括以下的几类词：</p>
<ul>
<li><strong>质量控制</strong>：画质、镜头效果、光照效果</li>
<li><strong>前置词</strong>：画风、艺术家、风格</li>
<li><strong>主体</strong>：人物&amp;对象、姿势、服装、道具</li>
<li><strong>场景</strong>：环境、背景、细节</li>
<li><strong>Additional Network</strong>：载入额外模型</li>
</ul>
<p><strong>分割符号：</strong> 各个关键词之间用 <code>,</code> 分割，且对应的权重从前到后依次递减，因此在编写关键词的时候也要注意先后顺序。</p>
<p><strong>权重加权符号</strong>：各种括号代表各种不同的加权系数，这里建议用 <code>(prompt: weight)</code> 统一来编写提示词的权重规则，整体可读性会更好。</p>
<p>这里的 weight 指的是权重变成原本的 weight 倍，就可以调整加强或减弱。</p>
<blockquote>
<p>各个括号的默认系数如下: () -&gt; 1.1 ; {} -&gt; 1.05 ; <code>[]</code> -&gt; 0.952<br>可以通过(())进行叠加即 1.1*1.1</p>
</blockquote></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/AI/">AI </a></div><a class="article-more button is-small is-size-7" href="/cn/StableDiffusionPrompt/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/StableDiffusionControlNet/"><img class="fill" src="/img/header_img/lml_bg40.jpg" alt="AIGC03 Stable Diffusion Control Net"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/StableDiffusionControlNet/"><i class="fas fa-angle-double-right"></i>AIGC03 Stable Diffusion Control Net</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-04-26T13:19:41.000Z" title="2023-04-26T13:19:41.000Z">2023-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:27:54.293Z" title="2023/10/31 08:27:54">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/AIGC/">AIGC</a></span><span class="level-item">8 minutes read (About 1195 words)</span></div></div><div class="content"><blockquote>
<p>ControlNet 是 Stable Diffusion 最强力的插件之一，它能够控制 SD 的整个扩散过程，包括让 AI 参考动作/骨架/线条/景深，从而更精准的生成图片。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/extensions/controlnet/">ControlNet 按照骨架動作繪圖 | Stable Diffusion WebUI使用手冊</a></li>
<li><a target="_blank" rel="noopener" href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/extensions/posex/">骨架人偶 PoseX | Stable Diffusion WebUI 使用手冊</a></li>
<li><a target="_blank" rel="noopener" href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/extensions/latent-couple/">生成多個人物 Latent Couple | Stable Diffusion WebUI使用手冊</a></li>
<li>拓展地址：<a target="_blank" rel="noopener" href="https://github.com/Mikubill/sd-webui-controlnet">Mikubill/sd-webui-controlnet: WebUI extension for ControlNet (github.com)</a></li>
<li>ControlNet 地址：<a target="_blank" rel="noopener" href="https://github.com/lllyasviel/ControlNet">lllyasviel/ControlNet: Let us control diffusion models! (github.com)</a></li>
<li>模型地址：<a target="_blank" rel="noopener" href="https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main">lllyasviel/ControlNet-v1-1 at main (huggingface.co)</a></li>
</ul></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/AI/">AI </a></div><a class="article-more button is-small is-size-7" href="/cn/StableDiffusionControlNet/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Stable%20Diffusion%20%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/"><img class="fill" src="/img/header_img/lml_bg41.jpg" alt="AIGC02 Stable Diffusion 基础功能介绍"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Stable%20Diffusion%20%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/"><i class="fas fa-angle-double-right"></i>AIGC02 Stable Diffusion 基础功能介绍</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-04-26T03:03:56.000Z" title="2023-04-26T03:03:56.000Z">2023-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/AIGC/">AIGC</a></span><span class="level-item">19 minutes read (About 2885 words)</span></div></div><div class="content"><blockquote>
<p>本篇章介绍关于 Stable DIffusion 的一些基础概念和 WebUI 的基本功能元素，同时介绍一些启动项和模型加载的东西。</p>
</blockquote>
<h2 id="启动项设置（局域网）"><a href="#启动项设置（局域网）" class="headerlink" title="启动项设置（局域网）"></a>启动项设置（局域网）</h2><p>最常用的启动项是 <code>--listen</code>，通过该启动项允许局域网内的其他设备通过 ip 和端口访问部署好的 Stable Diffusion 服务。而设置启动项的方式有以下几种：</p>
<ol>
<li>命令行执行启动脚本的时候携带</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">./webui.bat <span class="hljs-literal">--listen</span><br><span class="hljs-comment"># ./webui.sh --listen</span><br></code></pre></td></tr></table></figure>
<ol>
<li>修改主入口脚本中的启动选项 <code>vim launch.py</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 修改下面这一行的参数, 将&quot; &quot;中填入需要的参数</span><br><span class="hljs-comment"># commandline_args = os.environ.get(&#x27;COMMANDLINE_ARGS&#x27;, &quot;&quot;)</span><br>commandline_args = os.environ.get(<span class="hljs-string">&#x27;COMMANDLINE_ARGS&#x27;</span>, <span class="hljs-string">&quot;--listen&quot;</span>)<br></code></pre></td></tr></table></figure>
<ol>
<li>其他的启动项介绍可以参考：<a target="_blank" rel="noopener" href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/installation/command-line-arguments-and-settings/">2.3. 命令列引數 | Stable Diffusion WebUI使用手冊(正體中文)｜Ivon的部落格 (ivonblog.com)</a></li>
</ol></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/AI/">AI </a></div><a class="article-more button is-small is-size-7" href="/cn/Stable%20Diffusion%20%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Stable%20Diffusion/"><img class="fill" src="/img/header_img/lml_bg10.jpg" alt="AIGC01 Stable Diffusion and midjourney Setup"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Stable%20Diffusion/"><i class="fas fa-angle-double-right"></i>AIGC01 Stable Diffusion and midjourney Setup</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-04-19T08:00:00.000Z" title="2023-04-19T08:00:00.000Z">2023-04-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/AIGC/">AIGC</a></span><span class="level-item">9 minutes read (About 1356 words)</span></div></div><div class="content"><blockquote>
<p>This Chapter introduce how to set up stable diffusion and mid-journey, and record some problem I meet when I deploy it. </p>
</blockquote>
<h2 id="Deprecated-midjourney"><a href="#Deprecated-midjourney" class="headerlink" title="(Deprecated) midjourney"></a>(Deprecated) midjourney</h2><blockquote>
<p>由于 midjourney 现需要付费使用，同时没有开源，因此我们讲一笔带过该部分内容，该部分内容大多转载于  <a target="_blank" rel="noopener" href="https://www.uisdc.com/midjourney">超详细！AI 绘画神器 Midjourney 基础使用手册</a></p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://midjourney.com/home/?callbackUrl=%2Fapp%2F">midjourney</a> 的安装步骤主要分成以下的几步：</p>
<ol>
<li>点击 Join the Beta 注册账号，注册完会跳转到；</li>
<li>Discord 首页，亲自创建自己的服务器，仅供我和我的朋友使用；</li>
<li>下载客户端，在默认对话界面讯在或开始新的对话，输入 Midjourney Bot，添加到服务器</li>
<li>付费开启体验。</li>
</ol>
<h2 id="Deprecated-DreamStudio"><a href="#Deprecated-DreamStudio" class="headerlink" title="(Deprecated) DreamStudio"></a>(Deprecated) DreamStudio</h2><blockquote>
<p>说是可以本地部署，但是实际体验非常不好，应该只是部署了 Webui，然后调用官方提供的免费 API；所以有时候生成不出来，但是又不报错，不知道是不是使用姿势有问题，反正很屎。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Stability-AI/StableStudio">https://github.com/Stability-AI/StableStudio</a></li>
<li>装好 npm 和 yarn</li>
<li>参考 quick start，git clone -&gt; (cd) yarn 安装 -&gt; yarn dev 部署在本地端口上。</li>
<li>官网注册账号-&gt; 获取 API -&gt; 填入并在最上方转到 Generate 页面即可。</li>
</ul>
<h2 id="Stable-Diffusion-部署专题"><a href="#Stable-Diffusion-部署专题" class="headerlink" title="Stable Diffusion 部署专题"></a>Stable Diffusion 部署专题</h2><blockquote>
<p>该部分作为 Intro，仅介绍 Stable Diffusion 的安装和部署，以及一些启用参数等，具体的使用在后面的文章进行进一步的讲解。</p>
</blockquote>
<p><strong>基于官方 REPO</strong>： <a target="_blank" rel="noopener" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111/stable-diffusion-webui: Stable Diffusion web UI (github.com)</a></p>
<p>这里介绍基于 windows 的安装和 WSL2 的安装部署过程。整体的安装可能会分成以下的几个步骤进行：（推荐在安装和部署之前，参考 [[WindowsCudaCudnn]] 一文，首先配置 CUDA，也可以遇到问题再部署）</p>
<ul>
<li>基础依赖和环境安装（python、CUDA）</li>
<li>Stable DIffusion 的 UI 界面和部分插件安装</li>
<li>模型下载和加载</li>
</ul></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/AI/">AI </a></div><a class="article-more button is-small is-size-7" href="/cn/Stable%20Diffusion/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/FineTune/"><img class="fill" src="/img/header_img/lml_bg37.jpg" alt="Fine Tuning"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/FineTune/"><i class="fas fa-angle-double-right"></i>Fine Tuning</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-02-08T06:31:37.000Z" title="2022-02-08T06:31:37.000Z">2022-02-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 847 words)</span></div></div><div class="content"><p>@Langs: python, torch<br>@reference: d2l-pytorch，<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">transfer_torch</a></p>
<p>This Note focus on the code part.<br>模型微调和模型预训练，在Pytorch中的使用方式对比汇总。</p>
<h2 id="How-to-Design-the-Fine-Tune"><a href="#How-to-Design-the-Fine-Tune" class="headerlink" title="How to Design the Fine Tune"></a>How to Design the Fine Tune</h2><p>这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211205143153.png" alt="WorkFlow"></p>
<p>基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。</p>
<p>在Transfer任务中，有几种不同的调整方式：</p>
<ul>
<li>固定Bakcbone，只训练Classifier</li>
<li>同步微调网络</li>
<li>区分学习率，微调Backbone，训练Classifirer</li>
</ul>
<p>为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。</p>
<h2 id="Code-Part"><a href="#Code-Part" class="headerlink" title="Code Part"></a>Code Part</h2><h3 id="不同lr设置"><a href="#不同lr设置" class="headerlink" title="不同lr设置"></a>不同lr设置</h3><p><strong>微调Backbone，训练Classifier</strong>作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch, </a><a class="link-muted" rel="tag" href="/tags/Fine-Tune/">Fine-Tune </a></div><a class="article-more button is-small is-size-7" href="/cn/FineTune/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IL-Collection/"><img class="fill" src="/img/header_img/lml_bg9.jpg" alt="IL Collection"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IL-Collection/"><i class="fas fa-angle-double-right"></i>IL Collection</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-01-03T17:38:04.000Z" title="2022-01-03T17:38:04.000Z">2022-01-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:08:31.637Z" title="2023/10/31 08:08:31">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">29 minutes read (About 4422 words)</span></div></div><div class="content"><p>@AikenHong 2022</p>
<p>[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.</p>
<p>In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure.<br>在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_36474809/article/details/116176371">DER</a></li>
<li>SPPR 没有 get 到方法到底是怎么做的</li>
</ul>
<h2 id="Introduction-👿"><a href="#Introduction-👿" class="headerlink" title="Introduction 👿"></a>Introduction 👿</h2><p>在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。</p>
<p>Incremental 的基本过程可以表示如下<sub>[4]</sub>：<br><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/20220106101003.png" alt="dsa"></p>
<p>我们将模型可以划分为以下的两个部分<sub>[1]</sub>：backbone 和 classifier<br><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220105213925.png" alt="split"></p>
<p>从 LWF 中我们可以知道经典的 Paradigm，主要有下面的三种来对$\theta _S$ 和$\theta_o$来进行更新：</p>
<ul>
<li>仅重新训练分类器：仅更新$\theta_o$</li>
<li>微调特征提取器，重新训练分类器</li>
<li>联合训练</li>
</ul>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106111235.png" alt=""></p>
<h2 id="基于蒸馏架构的方法"><a href="#基于蒸馏架构的方法" class="headerlink" title="基于蒸馏架构的方法"></a>基于蒸馏架构的方法</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Incremental-Learning/">Incremental Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/IL-Collection/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IL-WYZ/"><img class="fill" src="/img/header_img/lml_bg29.jpg" alt="WYZ-IL-Collection"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IL-WYZ/"><i class="fas fa-angle-double-right"></i>WYZ-IL-Collection</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-01-03T02:41:56.000Z" title="2022-01-03T02:41:56.000Z">2022-01-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">7 minutes read (About 1123 words)</span></div></div><div class="content"><p>: hammer: 王耀智</p>
<h2 id="Regularization-系列方法"><a href="#Regularization-系列方法" class="headerlink" title="Regularization 系列方法"></a>Regularization 系列方法</h2><p>这类方法旨在添加一些正则化损失来解决 <code>catastrophic forgetting</code> 的问题。</p>
<h3 id="Weight-Regularization"><a href="#Weight-Regularization" class="headerlink" title="Weight Regularization"></a>Weight Regularization</h3><p>这类方法一般是对网络中每个参数的重要性进行评估，根据每个参数的重要性和梯度信息更新参数。</p>
<p>典型的文章为 <a target="_blank" rel="noopener" href="https://www.pnas.org/content/pnas/114/13/3521.full.pdf">EWC</a> .</p>
<blockquote>
<p>PS: 这类文章我也没有读过。</p>
</blockquote>
<h3 id="Data-Regularization"><a href="#Data-Regularization" class="headerlink" title="Data Regularization"></a>Data Regularization</h3><p>这类方法专注于记住特征表示，通常是结合 Hinton 的知识蒸馏损失函数使得模型记住旧类别的知识，解决 catastrophic forgetting。</p>
<p>推荐以下几篇文章：</p>
<ul>
<li><code>LwF</code>(Learning without forgetting)，这篇文章在我看来是增量学习的开山之作，第一次给增量学习找到了一个比较好的方向，也是第一次将知识蒸馏应用到增量学习上；</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.13513">PODNet CVPR2020</a> ，这篇文章最大的贡献在我看来是设计了一个全新的蒸馏损失函数，最终结果也是达到了当时的sota，甚至目前也是几个榜单的sota。</li>
</ul>
<h2 id="Rehearsal-系列方法"><a href="#Rehearsal-系列方法" class="headerlink" title="Rehearsal 系列方法"></a>Rehearsal 系列方法</h2><p>这类方法主要的想法是使用一些旧类别的数据，在新类别到来时使用新旧数据一起训练模型，根据旧类别数据的真假分为以下两种方法。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Incremental-Learning/">Incremental Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/IL-WYZ/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/LT-Collection/"><img class="fill" src="/img/header_img/lml_bg27.jpg" alt="LT Collection"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/LT-Collection/"><i class="fas fa-angle-double-right"></i>LT Collection</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-22T06:36:16.000Z" title="2021-12-22T06:36:16.000Z">2021-12-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:11:54.338Z" title="2023/10/31 08:11:54">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">26 minutes read (About 3848 words)</span></div></div><div class="content"><h1 id="LT-Collections"><a href="#LT-Collections" class="headerlink" title="LT-Collections"></a>LT-Collections</h1><p>@AikenHong 2021</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mitming/OpenLT">Code of must of those methods</a><br>We will analysis those tricks on LT situation, and Analysis why it works.<br>在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。</p>
<p>其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png" alt="LT"><br>通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合</p>
<p>首先介绍 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/416315017">bag of tricks</a> 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick</p>
<p>经过该文实验总结，Trick组合应该是<sub>[1]`</sub>：</p>
<ul>
<li>在前几个epoch应用input mixup数据增强，然后后面fine-tuning;</li>
<li>(基于CAM的)重采样来重新训练分类器;</li>
</ul>
<p>实际上就是MixUp + Two-Stage的策略，后续对<strong>Mix-up</strong>这个策略带来的作用要进行补充了解一下</p>
<h2 id="Rebalance"><a href="#Rebalance" class="headerlink" title="Rebalance"></a>Rebalance</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Long-Tailed-Learning/">Long-Tailed Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/LT-Collection/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Loss-NCE/"><img class="fill" src="/img/header_img/lml_bg35.jpg" alt="Loss-NCE"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Loss-NCE/"><i class="fas fa-angle-double-right"></i>Loss-NCE</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-22T05:39:55.000Z" title="2021-12-22T05:39:55.000Z">2021-12-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">17 minutes read (About 2506 words)</span></div></div><div class="content"><p>@AikenHong 2021</p>
<p>Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples.<br>该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。</p>
<h2 id="What’s-NCE-Loss"><a href="#What’s-NCE-Loss" class="headerlink" title="What’s NCE Loss"></a>What’s NCE Loss</h2><p>在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）</p>
<p>首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上<code>j==gt</code>的情况下外层+log也就是ceLoss，也就是 $logSoftmax$</p>
<script type="math/tex; mode=display">
S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}</script><p>然后看infoNCE，基础的对比学习损失可以写成：</p>
<script type="math/tex; mode=display">
L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]</script><p>其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带$T$的NCE，即InforNCE.</p>
<p>分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。</p>
<p>从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。</p>
<blockquote>
<p>但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。</p>
</blockquote>
<h2 id="How-it-Works"><a href="#How-it-Works" class="headerlink" title="How it Works"></a>How it Works</h2><p>NCE的思想是<strong>拉近相似的样本，推开不相近的样本</strong>，从而学习到一个好的<strong>语义表示空间</strong>，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。</p>
<p>考虑之前人脸匹配的研究，使用 “Alignment and Uniformity on the Hypersphere”中的Alignment and Uniformity，就是一个更好理解他的角度<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Loss/">Loss </a></div><a class="article-more button is-small is-size-7" href="/cn/Loss-NCE/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Loss-SmoothSharpen/"><img class="fill" src="/img/header_img/lml_bg37.jpg" alt="Loss-Smooth(Sharpen)"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Loss-SmoothSharpen/"><i class="fas fa-angle-double-right"></i>Loss-Smooth(Sharpen)</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-16T19:35:27.000Z" title="2021-12-16T19:35:27.000Z">2021-12-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:11:42.791Z" title="2023/10/31 08:11:42">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 974 words)</span></div></div><div class="content"><p>@AikenHong 2021<br>@topic</p>
<ul>
<li>smooth label (inception v2)</li>
<li>when does label smoothing help (nips 2019) </li>
<li>sharpen in semi-supervised in the future </li>
<li><a target="_blank" rel="noopener" href="https://github.com/seominseok0429/label-smoothing-visualization-pytorch?utm_source=catalyzex.com">offical code github</a></li>
</ul>
<p>不是一个通用的方法，在很多的任务上反而会导致掉点的现象，可以简单分析一下，汲取一下思想和Sharpen做对比，在这篇文章中，我们可以结合之前的人脸对比损失来进行分析。</p>
<h2 id="What’s-the-smooth-label"><a href="#What’s-the-smooth-label" class="headerlink" title="What’s the smooth label"></a>What’s the smooth label</h2><p>首先介绍在图像分类任务中对logits和Hard label做ce得到我们的损失，可以表现为如下的形式：</p>
<script type="math/tex; mode=display">
Loss = -\sum^{K}_{i=1}p_i \log(q_i)</script><p>由于我们的标签是一个hard label，实际上可以转化成一个one-hot，即</p>
<script type="math/tex; mode=display">
\begin{equation}
p_i = \left\{
\begin{array}{c1}
1 & i==gt \\
0 & i!=gt \\
\end{array} \right.
\end{equation}</script><p>而soft label实际上做的是将 1的位置变为$1-\alpha$，其他位置设置为$\alpha/(K-1)$，然后再去求CE，</p>
<p>Hinton论文中给出该损失对特征分布的作用测试图：<br><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211216194040.png" alt=""></p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Loss/">Loss </a></div><a class="article-more button is-small is-size-7" href="/cn/Loss-SmoothSharpen/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/NerualNetworkTraining/"><img class="fill" src="/img/header_img/lml_bg37.jpg" alt="Training Strategy"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/NerualNetworkTraining/"><i class="fas fa-angle-double-right"></i>Training Strategy</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-16T00:34:44.000Z" title="2021-12-16T00:34:44.000Z">2021-12-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">27 minutes read (About 4090 words)</span></div></div><div class="content"><p>@Aiken 2020，</p>
<p>主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。</p>
<p>参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。</p>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p><a target="_blank" rel="noopener" href="https://wizardforcel.gitbooks.io/learn-dl-with-pytorch-liaoxingyu/content/">Some Material</a><br>实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：</p>
<p>Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。</p>
<p>但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。</p>
<h2 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h2><p>$\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，</p>
<p>==Basic==</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>学习率大</th>
<th>学习率小</th>
</tr>
</thead>
<tbody>
<tr>
<td>学习速度</td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td>使用情景</td>
<td>刚开始训练时</td>
<td>一定的次数过后</td>
</tr>
<tr>
<td>副作用</td>
<td>1. Loss爆炸 2.振荡</td>
<td>1.过拟合 2.收敛速度慢</td>
</tr>
</tbody>
</table>
</div>
<h3 id="学习率的基本设置"><a href="#学习率的基本设置" class="headerlink" title="学习率的基本设置"></a>学习率的基本设置</h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch, </a><a class="link-muted" rel="tag" href="/tags/Acceleration/">Acceleration </a></div><a class="article-more button is-small is-size-7" href="/cn/NerualNetworkTraining/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Loss-WhyZero/"><img class="fill" src="/img/header_img/lml_bg27.jpg" alt="Loss-WhyZero"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Loss-WhyZero/"><i class="fas fa-angle-double-right"></i>Loss-WhyZero</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-10T00:24:46.000Z" title="2021-12-10T00:24:46.000Z">2021-12-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 776 words)</span></div></div><div class="content"><h1 id="Loss-Why-Zero-Loss？"><a href="#Loss-Why-Zero-Loss？" class="headerlink" title="Loss :Why Zero Loss？"></a>Loss :Why Zero Loss？</h1><p>@Comments: ICML2020 《Do We Need Zero Training Loss After Achieving Zero Training Error》</p>
<p>@Noteby：AikenHong2021</p>
<p>如何解决训练损失下降，但是验证损失上升的问题（过拟合like）的问题，该文章实际上可以作为我们损失设计中的一个trick，只需要简单的一行代码，来提升代码的泛化能力；</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211026211602.png" alt="img"></p>
<p>这张图体现了本文的灵魂（思路），主要体现在我们在算法趋于稳定后继续训练可能验证损失会反而上升；</p>
<p>所以本文提出了一种flooding方法，当我们training loss 大于阈值的时候我们使其正常下降，当低于阈值的时候，flooding的设计会反过来使得梯度上升，让训练损失保持在flooding附近，让模型持续进行random walk，希望模型最终能优化到一个平坦的损失区域，这样发现test loss进一步的进行下降。</p>
<p>理解：</p>
<p>当我们的训练损失低到一定的程度，然后随着lr的下降，模型会很难跳出当前的极小值，这种情况下我们的泛化能力也会被限制住，采用这种方法在牺牲测试精度的同时能提升算法的泛化能力。</p>
<p>损失公式表示如下</p>
<script type="math/tex; mode=display">
\widetilde{J}(\theta) = |J(\theta) - b| +b</script><p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211027104636.jpg" alt="v2-084a8f00d7349a94540fc7ad3a9433b0_r"></p>
<p>具体的代码表示只需要添加一层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">b = the flood num <br>new_loss = (loss - b).<span class="hljs-built_in">abs</span>() + b<br>optimizer.zero_grad()<br>new_loss.backward()<br>optimizer.step()<br></code></pre></td></tr></table></figure></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Loss/">Loss </a></div><a class="article-more button is-small is-size-7" href="/cn/Loss-WhyZero/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/UniFramework/"><img class="fill" src="/img/header_img/lml_bg16.jpg" alt="UniFramework 01"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/UniFramework/"><i class="fas fa-angle-double-right"></i>UniFramework 01</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-03T17:43:30.000Z" title="2021-12-03T17:43:30.000Z">2021-12-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:28:20.614Z" title="2023/10/31 08:28:20">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">30 minutes read (About 4430 words)</span></div></div><div class="content">Here's something encrypted, password is required to continue reading.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/UniFramework/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/FSL-Collection/"><img class="fill" src="/img/header_img/lml_bg28.jpg" alt="Survey for Few-Shot Learning"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/FSL-Collection/"><i class="fas fa-angle-double-right"></i>Survey for Few-Shot Learning</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:06:15.654Z" title="2023/10/31 08:06:15">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">43 minutes read (About 6448 words)</span></div></div><div class="content"><p>@aikenhong 2020<br>@h.aiken.970@gmail.com</p>
<p>另一个综述文章：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/61215293">https://zhuanlan.zhihu.com/p/61215293</a><br>对该文中一些内容有一些补充，可以看看</p>
<p>FSL简介：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xhw205/article/details/79491649">https://blog.csdn.net/xhw205/article/details/79491649</a></p>
<p>GCN用于FSL：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36022260/article/details/93753532">https://blog.csdn.net/qq_36022260/article/details/93753532</a></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>FSL的根本目的就是弥合人工智能和人类之间的鸿沟，从少量带有监督信息的示例中学习。像人类一样有很高的泛化能力。这也能解决在实际应用场景中，数据难以收集或者大型数据难以建立的情景。</p>
<p>FSL的<strong>核心问题</strong>是：经验风险最小化器不可靠；那么如何<strong>使用先验知识</strong>去解决这个问题？</p>
<p>三个主要的角度：</p>
<ol>
<li>数据：使用先验知识增强数据的监督经验</li>
<li>模型：使用先验知识来降低假设空间</li>
<li>算法：使用先验知识来改变搜索最佳假设（来进行搜索？)</li>
</ol>
<p>现阶段针对FSL提出的一些相关的机器学习方法：<br><code>meta-learning;</code> <code>embedding learning;</code>  <code>generative modeling etc.</code></p>
<p><strong>本文的主要工作：</strong><br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/FSL/">FSL </a></div><a class="article-more button is-small is-size-7" href="/cn/FSL-Collection/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/FSL%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/"><img class="fill" src="/img/header_img/lml_bg38.jpg" alt="FSL前期调研"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/FSL%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/"><i class="fas fa-angle-double-right"></i>FSL前期调研</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:06:43.838Z" title="2023/10/31 08:06:43">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">21 minutes read (About 3220 words)</span></div></div><div class="content">Here's something encrypted, password is required to continue reading.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/FSL/">FSL </a></div><a class="article-more button is-small is-size-7" href="/cn/FSL%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IL-MgSvF/"><img class="fill" src="/img/header_img/lml_bg3.jpg" alt="IL-MgSvF"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IL-MgSvF/"><i class="fas fa-angle-double-right"></i>IL-MgSvF</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">8 minutes read (About 1165 words)</span></div></div><div class="content"><p>@Author &amp; Paper：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.15524.pdf">Arxiv</a><br>@Note：Aikenhong 2021/11/12</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/cp_oldy/article/details/111714896">Other’s Note 1 </a></p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><strong>旧知识的缓慢忘记和新知识的快速适应的困境</strong>：主要探讨Incremental中的Old和New的相互牵制和适应的问题，</p>
<p>旧知识的缓慢遗忘会导致对新任务的欠拟合，而快速适应会导致灾难性的遗忘，如何对这两种策略之间进行权衡，是一个重要的问题。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211112114701.png" alt="image-20211112110043089"></p>
<p><strong>多尺度混合</strong>的解决这个问题：</p>
<ul>
<li>Intra-space： 新类别的特征在同一个特征空间中</li>
<li>inter-saoce：新旧类别的特征在不同的特征空间中</li>
</ul>
<p>本文提出的<strong>多粒度策略</strong>：</p>
<ol>
<li>提出了一种频率感知的正则化操作，加速空间内的增量学习能力</li>
<li>新的特征空间组合操作，提升空间间的学习性能</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Incremental-Learning/">Incremental Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/IL-MgSvF/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/SSL-MoCov3/"><img class="fill" src="/img/header_img/lml_bg4.jpg" alt="SSL-MoCov3"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/SSL-MoCov3/"><i class="fas fa-angle-double-right"></i>SSL-MoCov3</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">a minute read (About 162 words)</span></div></div><div class="content"><p>@Aiken 2021 </p>
<p>恺明大神对自监督学习+transformer的实证研究，针对Transformer再自监督学习学习框架中的训练不稳定问题提出了<strong>Random Patch Projection</strong>的解决方案。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/waqkJkwqxU-7utfNnwr2Gg">Article</a>；<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.02057">Paper</a>；</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>ViT的方法在自监督学习的任务中，精度下降的主要原因是由于算法的不稳定性，容易陷入局部的最优值，本文主要聚焦于<strong>采用视觉领域的自监督框架进行Transformer的训练</strong>，CNN的训练方法已经是一个比较明确约定俗称的方法，而Transformer的训练架构实际上还没有被完全的构建。</p>
</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/DataAugmentation/"><img class="fill" src="/img/header_img/lml_bg12.jpg" alt="Data Augmentation"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/DataAugmentation/"><i class="fas fa-angle-double-right"></i>Data Augmentation</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T22:24:20.000Z" title="2021-11-27T22:24:20.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">12 minutes read (About 1760 words)</span></div></div><div class="content"><p>intergrate with those augmentation method.</p>
<p>this doc will</p>
<ul>
<li>Record those theory and the effect after transformation</li>
<li>Show the codes for ez use</li>
</ul>
<p>And the complete <code>.py</code> will be intergrate in my classification pipeline</p>
<p><strong>reference</strong> below:arrow_down_small:, if use them,start it for respect for his work.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/aleju/imgaug#documentation">aleju/imgaug</a></li>
<li>:star:<a target="_blank" rel="noopener" href="https://github.com/albumentations-team/albumentations">albumentations-team/albumentations: </a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-and-torch-tensor">torchvision</a></li>
<li><a target="_blank" rel="noopener" href="https://pillow.readthedocs.io/en/stable/reference/ImageEnhance.html">PIL/ImageEnhance CCBS</a></li>
<li>opencv</li>
</ul>
<h2 id="Principle"><a href="#Principle" class="headerlink" title="Principle"></a>Principle</h2><p><strong>Principle 1</strong> of coding: Don’t reinvent the wheel unless it’s needed</p>
<ul>
<li>具体而言，仅在函数的拓展性较差，无法对其定制化，满足我们的日常需求的时候，我们会自行编写函数从而满足我们的需求，否则我们直接引用已知的库，提升我们的实现效率。</li>
</ul></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Augmentation/">Augmentation, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch </a></div><a class="article-more button is-small is-size-7" href="/cn/DataAugmentation/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MLFlow/"><img class="fill" src="/img/header_img/lml_bg38.jpg" alt="MLFlow"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MLFlow/"><i class="fas fa-angle-double-right"></i>MLFlow</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T22:24:19.000Z" title="2021-11-27T22:24:19.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">3 minutes read (About 397 words)</span></div></div><div class="content"><h1 id="MLFlow-机器学习系统的使用"><a href="#MLFlow-机器学习系统的使用" class="headerlink" title="MLFlow 机器学习系统的使用"></a>MLFlow 机器学习系统的使用</h1><p>@Aiken 2020</p>
<p><em>基于Python开发的DAG数据工作流系统，面向机器学习，支持Spark并行环境和K8S容器集群；</em></p>
<p>MLFlow主要解决了三个问题，也就是三个我们可能会需要使用的功能：</p>
<ol>
<li><strong>Tracking</strong>：跟踪实验训练结果，记录算法参数，模型结果和运行效果等等；</li>
<li>Projects：对所有的算法项目有一套标准的projects概念，记录下代码版本，参数和运行环境这些东西，并且projects是可以拟合所有的算法框架的；</li>
<li>Models：解决的是打包和部署模型的这样一个行为，提供json接口给后续的flsk框架等等进行使用</li>
</ol>
<h2 id="基本部署"><a href="#基本部署" class="headerlink" title="基本部署"></a>基本部署</h2><p>INSTALL：</p>
<p>DEPLOY：</p>
<h2 id="Tracking-实验版本跟踪"><a href="#Tracking-实验版本跟踪" class="headerlink" title="Tracking 实验版本跟踪"></a>Tracking 实验版本跟踪</h2><p><strong>Tracking</strong>为本次描述的重点，来做一个训练过程中的版本管理，记录每一次训练的参数和变量信息等等，这样便于后续的恢复和实验信息的整理。便于统计和管理。使用的时候好像也是需要代码嵌入的部分，就是需要在代码中调用MLFlow的API。</p>
<p>但是在Tracking的时候有一个比较重要的点在于，这个方法和<code>Tensorboard</code>对原模型的参数的嵌入和Logging记录中<u>会不会产生冲突</u>，同时两个方法之间是不是有什么overlap；关键的问题：</p>
<ul>
<li>这两个API能不能进行混合使用</li>
<li>怎么统一和区分两个方法的应用情景</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/MLFlow/">MLFlow </a></div><a class="article-more button is-small is-size-7" href="/cn/MLFlow/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/HardTask/"><img class="fill" src="/img/header_img/lml_bg12.jpg" alt="Hard Task Sampling"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/HardTask/"><i class="fas fa-angle-double-right"></i>Hard Task Sampling</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T22:24:17.000Z" title="2021-11-27T22:24:17.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 876 words)</span></div></div><div class="content"><h1 id="Trick：Hard-Task"><a href="#Trick：Hard-Task" class="headerlink" title="Trick：Hard Task"></a>Trick：Hard Task</h1><p>思路来源于Meta-Tranfer-Learning，基本思路是在Meta-Learning的每一次Meta-Test的时候，会从预训练错误率比较高的Task中再次采样，增加那些task的训练次数。也就是难题多做的策略。</p>
<h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><h3 id="对比Adaboost"><a href="#对比Adaboost" class="headerlink" title="对比Adaboost"></a>对比Adaboost</h3><p>这样的思路其实和AdaBoost的想法是有一定的异曲同工之妙的，或者说其实就是AdaBoost的思路：</p>
<p><strong>Adaboost</strong></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/39972832">参考笔记</a>，从该笔记中我们可以看到，AdaBoost的基本思路如下：</p>
<blockquote>
<p>Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来<strong>更新训练样本的权重</strong>，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些<strong>误差率高的点</strong>在后面的弱学习器2中<strong>得到更多的重视</strong>。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器.</p>
</blockquote>
<p>和Meta-Transfer-Learning对比一下，我们可以发现，这个方法实际上就是讲Transfer Learning的与训练网络当成弱学习器1，然后通过弱学习器1的训练样本权重，来增大Hard-Task的配比（也就是增加任务的权重）完全一致。</p>
<h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><p>实现上主要是，样本sample的过程，就是如何在进行参数选择后和原本的Dataloader，结合起来。在这里我们主要参考MTL中的方法，进行网络的构建处理。</p>
<p>第一部分：<strong>sampler构建</strong>，为了后续Dataloader中进行数据的采样，需要构建一个这样的sampler，关键在于index的对应关系，以及最后输出的是index的集合。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Algorithm/">Algorithm, </a><a class="link-muted" rel="tag" href="/tags/Sampling/">Sampling </a></div><a class="article-more button is-small is-size-7" href="/cn/HardTask/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/"><img class="fill" src="/img/header_img/lml_bg34.jpg" alt="并行训练"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/"><i class="fas fa-angle-double-right"></i>并行训练</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T18:20:31.000Z" title="2021-11-27T18:20:31.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 794 words)</span></div></div><div class="content"><p><a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2021/09/24/train-large-neural-networks.html">How to Train Really Large Models on Many GPUs? (lilianweng.github.io)</a></p>
<p>对于浮点运算，模型参数的存储和中间计算输出（梯度和优化器状态）的存储的在 GPU 内存上的大量需求使得我们需要并行化，下面我们参考一些常用的并行化范式：</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch </a></div><a class="article-more button is-small is-size-7" href="/cn/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MIM-V-simMIM/"><img class="fill" src="/img/header_img/lml_bg29.jpg" alt="MIM-V-simMIM"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MIM-V-simMIM/"><i class="fas fa-angle-double-right"></i>MIM-V-simMIM</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-22T22:38:19.000Z" title="2021-11-22T22:38:19.000Z">2021-11-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">9 minutes read (About 1339 words)</span></div></div><div class="content"><p>@Author： MSRA Zhenda Xie<br>@Source：<a href="arxiv.org/abs/2111.09886">Arxiv</a>， <a target="_blank" rel="noopener" href="https://github.com/microsoft/SimMIM">Code TBP</a>，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/4YVYM9lPYghtZFhyOGnERw">Blog_CVer</a><br>@Read：AikenHong 2021.11.22</p>
<p>“What I cannot create, I do not understand.” — Richard Feynman</p>
<h2 id="Intro-amp-Simple-Conclusion"><a href="#Intro-amp-Simple-Conclusion" class="headerlink" title="Intro &amp; Simple Conclusion"></a>Intro &amp; Simple Conclusion</h2><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>继MAE和iBoT之后，MSRA也提出了一个图像掩码建模的新框架，SimMIM，该方法简化了最近这些提出的方法，不需要特殊设计，作者也验证了不需要那些特殊设计就已经能让模型展现出优秀的学习能力</p>
<ul>
<li>采用中等大小的掩码块（32），对输入图像进行随机掩码，能使其成为强大的代理任务（pretext task）</li>
<li>直接回归预测原始像素的RGB值的效果并不比复杂设计的Patch分类方法差</li>
<li>Projector Head可以是轻量的Linear Layer，效果并不一定比MLP（多层）的差</li>
</ul>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>通过这种MIM方法可以实现在大量无标注的数据上得到一个表征能力up的通用特征模型，这种方式的backbone可以广泛的应用到图像上的各种子任务中（按照NLP）的经验来说，而为了类似的方式在图像上的大放异彩，我们首先需要分析Vision和Language的不同</p>
<ol>
<li><strong>图像有更强的局部关系</strong>：相互靠近的像素是高度相关和近似的，我们可以通过简单的copy padding复制一部分缺失</li>
<li><strong>视觉信号是原始，低层次的，而文本分词是高级概念</strong>：对低层次信号的预测是否对高层次的视觉识别任务有用呢？</li>
<li><strong>视觉信号是连续的，而文本的分词是离散的</strong>： 如何基于分类的掩码语言建模方法来处理连续的视觉信号</li>
</ol>
<h2 id="Theoretical-Design"><a href="#Theoretical-Design" class="headerlink" title="Theoretical Design"></a>Theoretical Design</h2><p><strong>掩码选择</strong>：同样的掩码的策略还是基于Patch进行的，对于掩码的设计来说，太大的掩码快或者太密集的掩码快，可能会导致找不到附近的像素来预测，实验证明32是一个具有竞争力的size，和文本任务的信息冗余程度不同也带来了覆盖比的选择，NLP通常是0.15，而在V中，32size可以支持0.1-0.7的覆盖率。</p>
<p><strong>任务选择</strong>：使用原始像素的回归任务，因为回归任务和具有有序性的视觉信号的连续性很好的吻合。</p>
<p><strong>预测头选择</strong>：使用轻量的预测头如（linear），迁移性能与繁琐的预测头相似或者略好，同时训练上更加的块。虽<strong>然较大的头或更高的分辨率通常会导致更强的生成能力，但这种更强的能力不一定有利于下游的微调任务</strong>。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/MIM-V-simMIM/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Transformer/"><img class="fill" src="/img/header_img/lml_bg10.jpg" alt="Transformer"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Transformer/"><i class="fas fa-angle-double-right"></i>Transformer</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-22T22:38:19.000Z" title="2021-11-22T22:38:19.000Z">2021-11-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">4 minutes read (About 636 words)</span></div></div><div class="content"><p>@aikenhong 2021   </p>
<p>References For Transformer:</p>
<ol>
<li>NLP <a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html">The Transformer Family (lilianweng.github.io)</a></li>
<li>VIT <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MjM5ODExNDA2MA==&amp;mid=2449941486&amp;idx=1&amp;sn=336a47a31f4b4ff0f6cd8e2fc3cb184a&amp;chksm=b13c258d864bac9b32d10ec36a058d77cc7cf90e066e76ae476fd2fde1b54256cd608a559bb6&amp;mpshare=1&amp;scene=23&amp;srcid=1101rcBaNzO4pu00PCPsJOAl&amp;sharer_sharetime=1635744838591&amp;sharer_shareid=ec299f1c891fc72cd699f8eaeb8a0cd5#rd">Transformer眼中世界 VS CNN眼中世界</a></li>
<li>李沐 NLP <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1pu411o7BE?spm_id_from=333.999.0.0">Transformer论文精读</a></li>
<li>Suveys <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&amp;mid=2247514162&amp;idx=2&amp;sn=d094eecbfd91ca1e478c41e29f2b98d5&amp;scene=21#wechat_redirect">cver1</a>， <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&amp;mid=2247514982&amp;idx=2&amp;sn=7e38021234b7ab5455429e4485128efd&amp;chksm=f9a1c9e9ced640ff045d1c4fe9d4e98a785602d980b25df4fa18477dd2b4b829ed4fc3fd028f&amp;scene=21#wechat_redirect">cver2</a>，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/_th7rXfZDuSu2xo7gdPp0w">cver3</a></li>
</ol>
<p>This blog will divided into several part : lil’s blog, the survey for ViT, we using those article to help us understand the transformer.</p>
<p>综述我们以最新的一篇为准进行阅读，其他的可能后续进行查缺补漏把，如无必要，勿增烦恼。</p>
<h2 id="Intro导言"><a href="#Intro导言" class="headerlink" title="Intro导言"></a>Intro导言</h2><p>主要参考文章2来进行我们简单的导入</p>
<h3 id="基本问题"><a href="#基本问题" class="headerlink" title="基本问题"></a>基本问题</h3><p>Transformer原本是NLP中的重要模型, 作为LSTM的后继者, 用于处理Seq2Seq的数据类型和情景, 若是要将Transformer运用到Vision的领域中, 首要的问题就是如何:</p>
<p><strong>将Image作为序列化的Token输入Transform中</strong> , 而达成这个目的主要有三种典型的方法:</p>
<ul>
<li>像素点作为token,</li>
<li>使用VAE离散化图片作为token再输入</li>
<li>ViT: 将图片切为一个个<code>Patch</code>在经过线性的<code>projector</code>之后组成一个<code>embedding</code>表示进行交互</li>
</ul>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211120010516" alt="图片"></p>
<h3 id="CNN的异同分析"><a href="#CNN的异同分析" class="headerlink" title="CNN的异同分析"></a>CNN的异同分析</h3><p>差异分析和计算主要靠CKA向量相似度计算来计算模型和表征之间的差异，这里的理论分析暂且不赘述，后续有需求的话可参考论文Similarity of neural network representations revisited或当前文章.<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/Transformer/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MIM-V-iBOT/"><img class="fill" src="/img/header_img/lml_bg15.jpg" alt="MIM-V-iBOT"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MIM-V-iBOT/"><i class="fas fa-angle-double-right"></i>MIM-V-iBOT</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-17T22:35:52.000Z" title="2021-11-17T22:35:52.000Z">2021-11-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 823 words)</span></div></div><div class="content"><p>@Read: AikenHong 2021</p>
<p>@Author: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.07832">https://arxiv.org/abs/2111.07832</a></p>
<p>@解读：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/x4yEfg9eqW6x3Ehxm1HkRA">Machine Heart</a></p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>基于NLP中的MLM(Masked Language Model)的核心训练目标: 也就是遮住文本的一部分, 然后通过模型去预测和补全, 这一过程是模型学到泛化的特征, 使用这种方法来进行大规模的与训练范式.</p>
<p>在基本的思想上和MAE采用的是一样的设计, 但是本文中坐着认为visual tokenizer的设计才是其中的关键.</p>
<blockquote>
<p>不同于 NLP 中 tokenization 通过离线的词频分析即可将语料编码为含高语义的分词，图像 patch 是连续分布的且存在大量冗余的底层细节信息。而作者认为一个能够提取图像 patch 中高层语义的 tokenizer 可帮助模型避免学习到冗余的这些细节信息。作者认为视觉的 tokenizer 应该具备两个属性：（a）具备完整表征连续图像内容的能力；(b) 像 NLP 中的 tokenizer 一样具备高层语义。</p>
</blockquote>
<p>文中对tokenizer的设计为一个知识蒸馏的过程:</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211118151616.png" alt="image-20211118151613545"></p>
<p>文中使用这种在线tokenizer同时来监督这样的MIM过程, 也就是两部分协同学习, 能够较好的保证语义的同时并将图像内容转化为连续的特征分布, 具体的, tokenizer和目标网络狗狗想网络结构, 有移动平均来得到实际的tokenizer.</p>
<p>该形式近期在 DINO [3]中以自蒸馏被提出，并被用以针对同一张图片的两个不同视野在 [CLS] 标签上的优化：</p>
<script type="math/tex; mode=display">
L_{CLS} = - P_{\theta^`}^{[CLS]}(v)^T logP_{\theta}^{[CLS]}(\mu)</script><p>在该损失函数的基础上, MIM同样也是用这种自蒸馏的方式去优化, 其中在线tokenizer的参数为目标网络历史参数的平均.</p>
<script type="math/tex; mode=display">
L_{MIM} = - \sum_{i=1}^Nm_i *P_{\theta^`}^{patch}(\mu_i)^TlogP_{\theta}^{patch}(\hat{\mu}_i)</script><p>基于上述的这些训练目标，提出了一种自监督预训练框架iBOT， 同时优化两种损失函数。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/MIM-V-iBOT/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MIM-V-MAE/"><img class="fill" src="/img/header_img/lml_bg43.jpg" alt="MIM-V-MAE"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MIM-V-MAE/"><i class="fas fa-angle-double-right"></i>MIM-V-MAE</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-15T04:25:45.000Z" title="2021-11-15T04:25:45.000Z">2021-11-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">3 minutes read (About 504 words)</span></div></div><div class="content"><p>@Author：Facebook AI Research-Kaiming He<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/432663453">Kaiming-MAE</a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>总而言之这是一种大模型的训练方法, 通过在少量数据的基础上实现大模型的训练.</p>
<p>整体的架构上是参考了NLP中的AutoEncoder机制，将原图切分patch，用mask掩盖原图，通过少量可见的Patch进行Encoder后和Mask融合，再通过<strong>非对称</strong>的Decoder进行pixel的还原。</p>
<p>这种设计的有点在于mask的scala是可变的，同时这种mask能减少我们训练过程中对显存和计算复杂度的损耗，同时问题本身是一个比较复杂的问题，得以训练复杂的大模型，这种方式最终呈现的效果就是训练的效率高且效益好。</p>
<p>体现了自监督学习在这方面的优越性，同时这种方法得以实现也是由于ViT模型对于CNN模型的取代，才使得这种序列化切块的方式容易实现和验证。</p>
<p>这种方式在最终体现了自监督学习对于有监督与训练的优越性，使用这种方式能够更好的得到一个模型的通用表征。</p>
<p>在这里论文中也说明了和NLP的不同点以及这样的模型对于decoder的要求实际上是比NLP更高的</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211115113546.png" alt="image-20211115113542074"></p>
<h2 id="experiment"><a href="#experiment" class="headerlink" title="experiment"></a>experiment</h2><p><strong>Masking</strong>：对于输入的图像进行均匀的切分并均匀的随机采样</p>
<p><strong>MAE encoder</strong>: 简单的ViT模型，对输入图像进行编码后和Mask进行混合得到一个完整的令牌集合，从而确保Decode能够得到对应的位置信息。</p>
<p><strong>MAE decoder</strong>：轻量级的架构，可以独立于编码器进行设计，我们使用更窄更浅的网络，计算量比编码器10%更小，这样能够更快的进行训练。解码器的最后一层是先行投影，输出的数量==补丁中像素值的数量，最后会resize层原图的维度。</p>
</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/OWL-survey/"><img class="fill" src="/img/header_img/lml_bg15.jpg" alt="OWL-survey"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/OWL-survey/"><i class="fas fa-angle-double-right"></i>OWL-survey</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-12T01:40:46.000Z" title="2021-11-12T01:40:46.000Z">2021-11-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">14 minutes read (About 2062 words)</span></div></div><div class="content"><p>@AikenHong2021 OWL</p>
<p>分析现有的OWL特点，和当前自己的研究做一个区分，也汲取一下别人的研究的要点，</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.07848.pdf">self-supervised feature improve open-world learning</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/374268236">arxiv</a> @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.03526.pdf">open-world semi-supervised learning</a></li>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.12906.pdf">open-world learning without labels</a></li>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.05609.pdf">unseen class discovery in open-world classification</a></li>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2109.06628.pdf">Open-World Active Learning with Stacking Ensemble for Self-Driving Cars</a></li>
<li><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3308558.3313644">www</a> @ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011150266/article/details/118242627">open-world learning and application to product classification</a></li>
<li>cvpr @ <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mancini_Open_World_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf">open world composition zero-shot learning</a> </li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.02603.pdf">cvpr</a> @ <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356272271">Towards Open World Object Detection</a></li>
<li><a href="[Large-Scale Long-Tailed Recognition in an Open World (thecvf.com">cvpr</a>](<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.pdf</a>)) @ <a target="_blank" rel="noopener" href="https://github.com/zhmiao/OpenLongTailRecognition-OLTR">Large-Scale Long-Tailed Recognition in an Open World</a></li>
</ol>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><p><strong>Mulit Open world Learning Definition</strong></p>
<p>拒绝未见过的类的实例，逐步学习新的类扩展现有模型</p>
<h3 id="zap-Large-Scale-Long-Tailed-Recognition-in-an-Open-World"><a href="#zap-Large-Scale-Long-Tailed-Recognition-in-an-Open-World" class="headerlink" title=":zap: Large-Scale Long-Tailed Recognition in an Open World"></a>:zap: Large-Scale Long-Tailed Recognition in an Open World</h3><p><a target="_blank" rel="noopener" href="https://liuziwei7.github.io/projects/LongTail.html">Large-Scale Long-Tailed Recognition in an Open World (liuziwei7.github.io)</a></p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV, </a><a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Open-World-Learning/">Open World Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/OWL-survey/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/SS_OD_SoftTeacher/"><img class="fill" src="/img/header_img/lml_bg24.jpg" alt="SS_OD_SoftTeacher"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/SS_OD_SoftTeacher/"><i class="fas fa-angle-double-right"></i>SS_OD_SoftTeacher</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-08T18:30:08.000Z" title="2021-10-08T18:30:08.000Z">2021-10-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">9 minutes read (About 1398 words)</span></div></div><div class="content"><p>@ Article: ICML from Microsoft &amp; Huazhong Keda<br>@ Code: <a target="_blank" rel="noopener" href="https://github.com/microsoft/SoftTeacher">Github</a><br>@ Noteby: Aikenhong<br>@ Time: 20210914</p>
<h2 id="Abstrast-and-Intro"><a href="#Abstrast-and-Intro" class="headerlink" title="Abstrast and Intro"></a>Abstrast and Intro</h2><p>in the session we will using describe the main idea of this article.</p>
<p>这篇文章的重点在于Soft Teacher，也就是用pseudo label做为弱标注，逐步提高伪标签的可靠性。</p>
<p>不同于多阶段的方法，端到端的方法再训练中逐步的提升伪标签的质量从而再去benifit目标检测的质量。<br>这样E2E的框架主要依赖于两部分技术:</p>
<ul>
<li>soft teacher: 每个未标记边界框的分类损失由教师网络产生的分类分数进行加权</li>
<li>box jitter 窗口抖动: 选择可靠的伪框来学习框回归</li>
</ul>
<p>在目标检测上获得SOTA的效果;</p>
<h3 id="Multi-Stage"><a href="#Multi-Stage" class="headerlink" title="Multi-Stage"></a>Multi-Stage</h3><p>在半监督的情况下，关注的主要是基于伪标签的方法，是目前的SOTA，以往的方法采用多阶段的方式。</p>
<ol>
<li>使用标记数据训练初始检测器</li>
<li>未标记数据的伪标记，同时基于伪标签进行重新训练</li>
</ol>
<p><strong>局限</strong>：初始少量标注的局限，初始的检测器的伪标签质量</p>
<h3 id="End-to-End"><a href="#End-to-End" class="headerlink" title="End to End"></a>End to End</h3><p><strong>Soft Teacher</strong>基本思路：对未标记的图像进行标记，然后通过标记的几个伪标签训练检测器.<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Semi-Supervised-Learning/">Semi-Supervised Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/SS_OD_SoftTeacher/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/StyleGAN/"><img class="fill" src="/img/header_img/lml_bg18.jpg" alt="StyleGAN"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/StyleGAN/"><i class="fas fa-angle-double-right"></i>StyleGAN</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-03T05:16:40.000Z" title="2021-10-03T05:16:40.000Z">2021-10-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 879 words)</span></div></div><div class="content"><h1 id="StyleGAN-V1"><a href="#StyleGAN-V1" class="headerlink" title="StyleGAN V1"></a>StyleGAN V1</h1><p>@AikenHong 2020 10.8</p>
<p>《A Style-Based Generator Architecture for Generative Adversarial Networks》</p>
<h2 id="Related-Work："><a href="#Related-Work：" class="headerlink" title="Related Work："></a>Related Work：</h2><p>继承的文献工作： ProGAN<br>参考解读：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/a312863063/article/details/88795147">《其中子链接值得一看》</a>（包括源码解析啥的）（甚至还有GAN的笔记）</li>
<li><a target="_blank" rel="noopener" href="http://www.gwylab.com/pdf/Note_StyleGAN.pdf">《StyleGan源码解析和拓展应用》</a></li>
<li><a target="_blank" rel="noopener" href="https://cuijiahua.com/blog/2020/07/dl-22.html">《秃头生成器1》</a><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1658228">《秃头生成器2》 </a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/swlh/hairstyle-transfer-semantic-editing-gan-latent-code-b3a6ccf91e82">NO.3</a></li>
</ul>
<p>Contribution（Problem）：</p>
<ol>
<li>解纠缠：Mapping Network</li>
<li>Noise Generator</li>
<li>AdaIN before all conv</li>
</ol>
<h2 id="Structure："><a href="#Structure：" class="headerlink" title="Structure："></a>Structure：</h2><p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930135941.png" alt="image-20210930135938114"></p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930161259.png" alt="image-20210930161258031"></p>
<h3 id="Part1：AdaIN"><a href="#Part1：AdaIN" class="headerlink" title="Part1：AdaIN"></a>Part1：AdaIN</h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/GAN/">GAN </a></div><a class="article-more button is-small is-size-7" href="/cn/StyleGAN/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/YOLOv4/"><img class="fill" src="/img/header_img/lml_bg33.jpg" alt="YOLOv4"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/YOLOv4/"><i class="fas fa-angle-double-right"></i>YOLOv4</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-03T05:16:40.000Z" title="2021-10-03T05:16:40.000Z">2021-10-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">11 minutes read (About 1638 words)</span></div></div><div class="content"><p>@AikenHong 20200726</p>
<p>基于YOLO v4 掌握一些CV方面训练的<strong>Trick</strong>，同时针对Typora的使用进行一个熟悉掌握。<a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">GITHUB CODE</a></p>
<p>一些相关的参考资料</p>
<p>⚡️<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/150127712">https://zhuanlan.zhihu.com/p/150127712</a></p>
<p>⚡ <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650785604&amp;idx=1&amp;sn=46bd186e5291deded9f6ec1ae6a22649&amp;chksm=871a033ab06d8a2cff370a06e9e88f578a6c16a70231778ae2f997a8b30e347c6e746db10759&amp;mpshare=1&amp;scene=1&amp;srcid=0429kHitmMCPeF2JGN1XCzik&amp;sharer_sharetime=1588144165276&amp;sharer_shareid=484a4a951d2ad320314b6b56ee9a0ba8&amp;key=c53866ae67b2b8c4b46c89671357025dcdb6b895d1ebde603135230e484682a3552d924bf6126ecf72cb98361e1171f0f0381bee5bd456520dd201034c33ec48272d62ae73345cc914c2db9c6e943a10&amp;ascene=1&amp;uin=NTkyNDg4NjQw&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=ASfZUAGjes1A%2BJpXS1yNmT0%3D&amp;pass_ticket=GB56ClnZIrs5ENfLSAh4yF9tj54n041FM39bTg38LQuW%2FKDyBPyfqKLD8SDIZgE%2F">机器之心YOLOv4</a></p>
<p>⚡️<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/390191723/answer/1177584901">https://www.zhihu.com/question/390191723/answer/1177584901</a></p>
<p><strong>本文中一些其他的收获</strong></p>
<p>•  其他可替代的Object Detection的SOTA算法有哪些</p>
<p>•  BoS，BoF方法</p>
<p>•  简直是一个Tricks的综述</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些<strong>通用的**</strong>Trick<strong>**的组合</strong>尝试，包括</p>
<p>•  加权残差连接（WRC）</p>
<p>•  Cross-Stage-Partial-connection，CSP</p>
<p>•  Cross mini-Batch Normalization，CmBN</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/YOLOv4/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/categories/Machine-Learning/page/0/">Previous</a></div><div class="pagination-next"><a href="/categories/Machine-Learning/page/2/"> common.next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/categories/Machine-Learning/">1</a></li><li><a class="pagination-link" href="/categories/Machine-Learning/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/title.jpg" alt="AikenH"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">AikenH</p><p class="is-size-6 is-block">Future Full-Stack Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ShenZhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">131</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">98</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/AikenH" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="ZhiHu" href="https://www.zhihu.com/people/Aiken-h"><i class="fab fa-zhihu"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/1788200627"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Steam" href="https://steamcommunity.com/id/AikenH/"><i class="fab fa-steam"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/cn/deploy_server_byipv6_02_nginx/"><img src="/img/header_img/lml_bg11.jpg" alt="使用Ipv6部署服务02 Nginx和Https"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-06T12:49:16.000Z">2023-11-06</time></p><p class="title"><a href="/cn/deploy_server_byipv6_02_nginx/">使用Ipv6部署服务02 Nginx和Https</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/Windows%E7%AB%AF%E5%8F%A3%E5%BC%82%E5%B8%B8%E5%8D%A0%E7%94%A8/"><img src="/img/header_img/lml_bg9.jpg" alt="Windows端口异常占用"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-05T15:46:54.000Z">2023-11-05</time></p><p class="title"><a href="/cn/Windows%E7%AB%AF%E5%8F%A3%E5%BC%82%E5%B8%B8%E5%8D%A0%E7%94%A8/">Windows端口异常占用</a></p><p class="categories"><a href="/categories/Windows/">Windows</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/deploy_server_byipv6/"><img src="/img/header_img/lml_bg10.jpg" alt="使用Ipv6部署服务01 IPV6开启和设置"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-05T11:23:17.000Z">2023-11-05</time></p><p class="title"><a href="/cn/deploy_server_byipv6/">使用Ipv6部署服务01 IPV6开启和设置</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/Flashcard_template/"><img src="/img/header_img/lml_bg35.jpg" alt="Obsidian使用 Spaced Repetition 制作闪念卡片"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-10-27T16:39:59.000Z">2023-10-28</time></p><p class="title"><a href="/cn/Flashcard_template/">Obsidian使用 Spaced Repetition 制作闪念卡片</a></p><p class="categories"><a href="/categories/Editor/">Editor</a> / <a href="/categories/Editor/Obsidian/">Obsidian</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/vsocde_regexp/"><img src="/img/header_img/lml_bg31.jpg" alt="VsCode&#039;s RegExp Catch 正则捕获"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-10-19T08:53:03.000Z">2023-10-19</time></p><p class="title"><a href="/cn/vsocde_regexp/">VsCode&#039;s RegExp Catch 正则捕获</a></p><p class="categories"><a href="/categories/Editor/">Editor</a> / <a href="/categories/Editor/Vscode/">Vscode</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Acceleration/"><span class="tag">Acceleration</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention/"><span class="tag">Attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Augmentation/"><span class="tag">Augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Blog/"><span class="tag">Blog</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Clash/"><span class="tag">Clash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud/"><span class="tag">Cloud</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Colab/"><span class="tag">Colab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Configuration/"><span class="tag">Configuration</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cpp/"><span class="tag">Cpp</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Database/"><span class="tag">Database</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataset/"><span class="tag">Dataset</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dev/"><span class="tag">Dev</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Django/"><span class="tag">Django</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Draft/"><span class="tag">Draft</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DualSystem/"><span class="tag">DualSystem</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Env/"><span class="tag">Env</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FSL/"><span class="tag">FSL</span><span class="tag">2</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Game-Generate/"><span class="level-start"><span class="level-item">Game Generate</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Leetcode/"><span class="level-start"><span class="level-item">Leetcode</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Blog/"><span class="level-start"><span class="level-item">Blog</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Blog/Gitbook/"><span class="level-start"><span class="level-item">Gitbook</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Blog/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Dev/"><span class="level-start"><span class="level-item">Dev</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Dev/Devops/"><span class="level-start"><span class="level-item">Devops</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/Raspberry-pie/"><span class="level-start"><span class="level-item">Raspberry-pie</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/SSH/"><span class="level-start"><span class="level-item">SSH</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Docker/Containers/"><span class="level-start"><span class="level-item">Containers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Editor/Obsidian/"><span class="level-start"><span class="level-item">Obsidian</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Editor/Vim/"><span class="level-start"><span class="level-item">Vim</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Editor/Vscode/"><span class="level-start"><span class="level-item">Vscode</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Frontend/"><span class="level-start"><span class="level-item">Frontend</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Frontend/Vue/"><span class="level-start"><span class="level-item">Vue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Github/"><span class="level-start"><span class="level-item">Github</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/"><span class="level-start"><span class="level-item">Langs</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Langs/Bash/"><span class="level-start"><span class="level-item">Bash</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Cpp/"><span class="level-start"><span class="level-item">Cpp</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Markdown/"><span class="level-start"><span class="level-item">Markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Nodejs/"><span class="level-start"><span class="level-item">Nodejs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MacOS/"><span class="level-start"><span class="level-item">MacOS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">48</span></span></a><ul><li><a class="level is-mobile" href="/categories/Machine-Learning/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/Dataset/"><span class="level-start"><span class="level-item">Dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/NAS/"><span class="level-start"><span class="level-item">NAS</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/NAS/NAT/"><span class="level-start"><span class="level-item">NAT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Photography/"><span class="level-start"><span class="level-item">Photography</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Windows/APPs/"><span class="level-start"><span class="level-item">APPs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/Dual-System/"><span class="level-start"><span class="level-item">Dual System</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/Powershell/"><span class="level-start"><span class="level-item">Powershell</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/WSL2/"><span class="level-start"><span class="level-item">WSL2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Aiken&#039;s Blog</a><p class="is-size-7"><span>&copy; 2023 AikenH</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_pv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span> and <span id="busuanzi_container2_site_uv"><span id="busuanzi_value_site_pv">0</span>&nbsp;visits</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>