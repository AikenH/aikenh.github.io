<!doctype html>
<html lang="cn"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Attention Mechanism - AikenH Blogs</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Aiken Hong"><meta name="msapplication-TileImage" content="/img/pokemon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aiken Hong"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="@Aiken 2020.9.16 对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。"><meta property="og:type" content="blog"><meta property="og:title" content="Attention Mechanism"><meta property="og:url" content="http://aikenh.cn/cn/Attention/"><meta property="og:site_name" content="AikenH Blogs"><meta property="og:description" content="@Aiken 2020.9.16 对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。"><meta property="og:locale" content="cn"><meta property="og:image" content="http://aikenh.cn/img/header_img/lml_bg5.jpg"><meta property="article:published_time" content="2021-09-27T21:34:22.000Z"><meta property="article:modified_time" content="2023-10-30T09:27:38.000Z"><meta property="article:author" content="AikenH"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Attention"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://aikenh.cn/img/header_img/lml_bg5.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://aikenh.cn/cn/Attention/"},"headline":"Attention Mechanism","image":["http://aikenh.cn/img/header_img/lml_bg5.jpg"],"datePublished":"2021-09-27T21:34:22.000Z","dateModified":"2023-10-30T09:27:38.000Z","author":{"@type":"Person","name":"AikenH"},"publisher":{"@type":"Organization","name":"AikenH Blogs","logo":{"@type":"ImageObject","url":{"text":"Aiken's Blog"}}},"description":"@Aiken 2020.9.16 对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。"}</script><link rel="canonical" href="http://aikenh.cn/cn/Attention/"><link rel="icon" href="/img/pokemon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css" title="default"><link rel="alternate stylesheet" href="/css/cyberpunk.css" title="cyberpunk"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="AikenH Blogs" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aiken&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-lightbulb" id="night-icon"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/header_img/lml_bg5.jpg" alt="Attention Mechanism"></span></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>Attention Mechanism</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-27T21:34:22.000Z" title="2021-09-27T21:34:22.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">18 minutes read (About 2748 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><p>@Aiken 2020.9.16</p>
<p>对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。</p>
<span id="more"></span>
<p><strong>1.TODO-List：</strong></p>
<ul>
<li>根据Lil’Log的Attention？Attention！进行初步的整理</li>
<li>各个分类的具体含义分开整理，理解一部分整理一部分，可能结合实际的应用去整理吧。</li>
<li>其中很重要的一点是数学分析的部分，需要对数学原理进行整理和领会。</li>
</ul>
<h2 id="What’s-Attention-In-Deep-Learning"><a href="#What’s-Attention-In-Deep-Learning" class="headerlink" title="What’s Attention In Deep Learning"></a>What’s Attention In Deep Learning</h2><p>在某种程度上，注意力是由我么如何关注视觉图像的不同区域或者我们如何关联同一个句子中的不同单词所启发的：针对于问题的不同，我们会对图像的某些具体的区域重视（某些区域在视觉中呈现高分辨率，而另一些则是低分辨率的情况），或者句子中的某些词重视的情况。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911182724.png" alt="image-20210118210915289"></p>
<p>可以解释一个句子中紧密的上下文单词之间的关系，比如我们看到eating就会期待看到food，而color对于我们来说就没有那么重要。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911182729.png" alt="image-20210118210936862"></p>
<p>简而言之，深度学习中的注意力就是针对不同问题下的重要性权重的向量，比如我们根据关联性，给上面的每个单词赋予一个相关性的向量权重，然后基于注意力加权后的总和作为目标的近似值。</p>
<h2 id="What’s-Wrong-with-Seq2Seq-Model"><a href="#What’s-Wrong-with-Seq2Seq-Model" class="headerlink" title="What’s Wrong with Seq2Seq Model"></a>What’s Wrong with Seq2Seq Model</h2><p>seq2swq旨在将再encoder-decoder的架构下，将输入序列转换为新序列，对两个序列的长度没有要求。</p>
<ul>
<li>Encoder：将输入序列转换成固定长度的context vector，用来概括整个源序列的信息</li>
<li>Decoder：使用context vector初始化，来进行解码（转换）</li>
</ul>
<p>这样的Encoder和Decoder架构都是Recurrent Neural Networks，就像LSTM和GRU架构。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911182731.png" alt="image-20210118214147224"></p>
<p>缺陷：固定长度的context vector可能会导致序列信息的缺失，同时可能会无法记住长句子，同时也会丢失<strong>时序的对齐</strong>信息。所以Attention就诞生了。</p>
<p>:question:</p>
<h2 id="Born-for-Translation"><a href="#Born-for-Translation" class="headerlink" title="Born for Translation"></a>Born for Translation</h2><p>这几个部分的研究都是基于NMT自然机器翻译，来进行分析的（文本非图像）</p>
<p><strong>原本的E-D</strong>是通过Encoder的最后一个hidden states构建单个Context Vector，而<strong>Attention</strong><br>做的就是在Context Vec和Source之间建立一个Shortcut（简单的Feed Forword<br>Network），而源和目标的对齐由上下文向量来学习和控制。而上下文中应该consumes（包含）几个维度的信息</p>
<p>Encoder的hidden States；</p>
<p>Decoder的hidden States；</p>
<p>Source 和 Target之间的对齐信息；</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911182734.png" alt="image-20210119164039458"></p>
<p>Encoder Decoder实际上都是RNN的架构，S实际上就是H，隐层状态，Decoder对EOS输出了一个初始的预测Y以后，推进Decoder的进程。</p>
<p>双向的recurrent network（bidirectional RNN）使得Encoder隐态同时考虑前后单词。而在Decoder中</p>
<p> s<em>t = f(s</em>{t-1},y_{t-1},c_t)</p>
<p>其中上下文向量c_t是输入序列的隐态之和，通过alignment score来进行加权。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911182738.png" alt="image-20210119171524970"></p>
<p>$a_{t,i}$将作为输入i对输出t的隐态加权（相关性），在网络中共同训练，通过tanh来进行激活处理。Score则使用下面的策略：</p>
<script type="math/tex; mode=display">
score(st,hi)=v_a^Ttanh(Wa[st;hi])</script><p>其中V, W都是对齐模型中学到的参数</p>
<p>最终对齐完成以后就会是：</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183010.png" alt="image-20210120112808197"></p>
<h2 id="A-Family-of-Attention-Mechanism"><a href="#A-Family-of-Attention-Mechanism" class="headerlink" title="A Family of Attention Mechanism"></a>A Family of Attention Mechanism</h2><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>由于这个良好的理论基础和实现效果，以及对序列的良好兼容性，这样的算法就被很快的拓展到了计算机视觉的领域中。（学 科 交 叉）</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183207.png" alt="image-20210120162959426"></p>
<p>这些不同的score方法实际上就是对每个position上的input和当前位置（通常用上一个时刻的state）来进行相关性建模，针对这些相关性建模，来确定输入对于下一个状态的影响因子，也就是得到一个context向量。这实际上就是注意力机制的核心理念把。</p>
<p> Referred to as “concat” in Luong, et al,<br>2015 and as “additive attention” in Vaswani, et al,<br>2017.(^) It adds a scaling factor 1/n−−√1/n,<br>motivated by the concern when the input is large, the<br>softmax function may have an extremely small gradient, hard for efficient learning.</p>
<p>下面对一些更广泛类型的注意力机制做一个摘要性的总结</p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>这个已经在我的Onenote中整理过了，大概看看就好。这里只讲了一些应用上的点，</p>
<p>自我注意，内部注意力，也就是自我内部关联的注意力关系获取；</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183010.png" alt="image-20210120164912683"></p>
<h3 id="Soft-vs-Hard-Attention"><a href="#Soft-vs-Hard-Attention" class="headerlink" title="Soft vs Hard Attention"></a>Soft vs Hard Attention</h3><p>Image Caption《show, attend and tell》，CNN获取特征，LSTM解码器利用卷积功能来逐一生成单词。通过Attention 来学习权重，可视化如下：</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183524.png" alt="image-20210120165709998"></p>
<p>根据注意力是访问整个图像还是访问图像的一个patch来定义hard和soft attention。</p>
<p><strong>Soft Attention：</strong>就是普通的全图Attention，将权重放在图像的所有色块上，基本没啥区别</p>
<ul>
<li>Pro: 模型平滑容易微分</li>
<li>Con：expensive when the source image is large</li>
</ul>
<p><strong>Hard Attention：</strong>一次只处理一小块图像，其实就相当于用0/1去对图像区域进行<a target="_blank" rel="noopener" href="https://www.pianshen.com/article/86961257993/">硬编码</a>，只对一部分的图像进行处理，但是这种方式的技术实现我还是没什么概念，后面可以专门研究一下。</p>
<ul>
<li>Pro：推理计算需求比较小</li>
<li>Con：不可微分，需要用更复杂的技术来进行训练（例如variance reduction or reinforcement learning）</li>
</ul>
<h3 id="Global-vs-Loacal-Attention"><a href="#Global-vs-Loacal-Attention" class="headerlink" title="Global vs Loacal Attention"></a>Global vs Loacal Attention</h3><p>Global实际上就和soft是类似的，而局部注意力机制更像是hard和soft之间的一个融合，对改进hard使其可以微分；</p>
<blockquote>
<p>the model first predicts a single aligned position for the current target word<br>and a window centered<br>around the source position is then used to compute a context vector.</p>
</blockquote>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183441.png" alt="image-20210120171755507"></p>
<p>后面提到了一些神经图灵机的内容就是一些基本的计算机制，实际上可能是启发LSTM设计擦除算法设计的根源。</p>
<h2 id="Neural-Turing-Machines"><a href="#Neural-Turing-Machines" class="headerlink" title="Neural Turing Machines"></a>Neural Turing Machines</h2><h3 id="Attention-Mechanisms"><a href="#Attention-Mechanisms" class="headerlink" title="Attention Mechanisms"></a>Attention Mechanisms</h3><p>可以将权重的看作一个神经图灵机的寻址权重：（基于位置或者基于内容的两种方式）</p>
<p><strong>Content-based addressing:</strong></p>
<p>基于内容寻址的权重设置从输入行和存储行提取的键值向量之间的相似度来创建关注向量：权重的具体计算通过余弦相似度后进行softmax归一化来进行权重的分配。</p>
<p>另外通过β系数来放大或者减弱分布的焦点。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183438.png" alt="image-20210120215549507"></p>
<p><strong>Interpolation</strong><br>通过interpolation gate scalar $g_t$ 将生成的上下文向量和上一步生成的注意力权重进行混合</p>
<script type="math/tex; mode=display">
w^g_t = g_tw^c_t + (1-g_t)w_{t-1}</script><p><strong>Location-baesd addressing</strong><br>基于位置的寻址，对注意力向量中不同位置的值进行求和，通过对允许的整数偏移位置中的权重来进行参数加权。这相当于是一个一维卷积来测试偏移量。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183435.png" alt="image-20210120220824648"></p>
<p>然后对注意力的分布进行锐化处理，使用γ参数</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183433.png" alt="image-20210120221036004"></p>
<p>完整的注意力workflow为：</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183429.png" alt="image-20210120221108972"></p>
<h2 id="Pointer-Network"><a href="#Pointer-Network" class="headerlink" title="Pointer Network"></a>Pointer Network</h2><p>解决的是输入输出都是顺序数据的问题。</p>
<h2 id="Transformer-Introduction"><a href="#Transformer-Introduction" class="headerlink" title="Transformer Introduction"></a>Transformer Introduction</h2><p><strong>Attention is all u need</strong><br>：提出的重要的Transformer的这种架构，使得算法能够完全基于注意力机制，而不需要序列对齐的recurrent Network。</p>
<h3 id="Key-Value-and-Query"><a href="#Key-Value-and-Query" class="headerlink" title="Key,Value and Query"></a>Key,Value and Query</h3><p><strong>这一块还是详细解读一下，这里说的太粗略了，没讲清楚。</strong></p>
<p>Transformer的主要重要的架构在于multi-head和self-attention，Transformer将输入堪称一个key-value pairs，均为输入长度n。</p>
<script type="math/tex; mode=display">
Attention(Q,K,V)=softmax(\frac{Q K^⊤} {\sqrt{n}})V</script><p>Key Value Query 到底都是些什么东西。</p>
<h2 id="Encoder-Decoder-and-Taxonomy-of-Attention"><a href="#Encoder-Decoder-and-Taxonomy-of-Attention" class="headerlink" title="Encoder-Decoder and Taxonomy of Attention"></a>Encoder-Decoder and Taxonomy of Attention</h2><p>基本的encoder-decoder是基于对序列处理的问题提出的，通常情况下针对的是输入输出都是序列的计算模型。下图a展示了<strong>典型的E-D机制</strong>，以及加入了self-attention的情况b。（文中提到了一些E-D机制的问题）</p>
<blockquote>
<p>Seq2Seq的RNN序列模型Encoder需要把之前的输入最终转化成单一的ht（定长），可能会造成序列信息的丢失，同时他只能<strong>平权的</strong>考虑输入，不能有所<strong>重点</strong>。同时对于<strong>时序对齐</strong>信息也会丢失，这对结构化特别重要</p>
</blockquote>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183425" alt="img"></p>
<p>注意力机制，在实现上就是通过在体系架构中，嵌入一个额外的前馈神经网络，来进行学习额外的参数（作为Decoder的补充输入，作为序列和之前信息的补充），而且通常，这个前馈的神经网络是需要和encoder-decoder协同训练的，也就是需要和整体网络<strong>共同训练</strong>。</p>
<blockquote>
<p>训练层面是否存在一些特殊的情况，对于一些特殊的Attention 模型，是否需要一些特殊的训练机制。这点如果看到的话，建议需要整理一下</p>
</blockquote>
<p>在<strong>Survey</strong>中，对注意力机制基于多种标准进行了分类，具体的分类情况可以依下图所示，还有一些具体方法的实现。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183358" alt="img"></p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183402.png" alt="uploading-image-657692.png"></p>
<p> 对于几种分类方式，可以参考几个译文的解读，但是我觉得说的并不清楚，后续就分别针对各种方法进行分析吧。</p>
<p>BTW：在RNN等循环结构不能并行化处理的条件下，提出的类似AM的<strong>Transformer</strong>（Attention is all u<br>need）结构，他的encoder和decoder由两个子层堆叠而来：Feed Forward Network 和 Multi-head self attention。</p>
<blockquote>
<p>Position-wise FFN：获取输入的顺序，在encoder阶段，对于每一个token既生成content embedding也生成position encoding。</p>
<p>Multi-Head Self-Attention：在每个子层中使用self - attention来关联标记及其在相同输入序列中的位置，几个注意力层并行堆叠，对于相同的输入有不同的线性转换。这使得模型能够捕获输入的不同方面，提高表达能力。</p>
</blockquote>
<h2 id="Transformer-and-Self-Attention"><a href="#Transformer-and-Self-Attention" class="headerlink" title="Transformer and Self-Attention"></a>Transformer and Self-Attention</h2><p>参考论文以及参考资料1 AND 《Attention is all you need》</p>
<p><strong>Self-Attention ：</strong></p>
<p>下图这一段整的明明白白，把整个框架说的比较明白，对输入的embedding（分别做3次卷积，图像输入的情况），分成Query，Key，Value，然后如图进行后续的操作</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183407.png" alt="image-20200926224839989"><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911183414.png" alt="image-20200927160231116"></p>
<p>图2就表示了在CV领域，为什么需要将输入做完卷积以后再成进去，而其中的scale由于图片和序列是不一致的，他们的size本来就是统一的（基本规范的数据集中），那么就可以省略掉这一步，从而直接进行softmax，相当于在预处理的时候已经进行了这样的归一操作。</p>
<p>self-attention 是 Transformer的基础，通过<strong>多个Self-Attention组成的Multi-head Attention</strong> 就是Transformer模型的基本结构。</p>
<p>Multi-head Attention</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>参考资料</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/47282410">Attention机制详解2：self-attention &amp; Transformer</a></p>
<p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/">origin document of ↑</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8115c7cebc59">Attention的数学原理</a></p>
<p>Survey:</p>
<ul>
<li><p>《An Attentive Survey of Attention Models》 mendeley</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ydcode/p/11040811.html">论文翻译和解读1</a>  :zap:</p>
</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_29305911/article/details/89380387">论文解读和翻译2</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/62445564">论文解读和翻译3</a></li>
</ul>
<p>Transformer:</p>
<ul>
<li>《Attention is all you need》Mendeley &amp;OneNote</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Attention Mechanism</p><p><a href="http://aikenh.cn/cn/Attention/">http://aikenh.cn/cn/Attention/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>AikenH</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-09-28</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-10-30</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Attention/">Attention </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/alipay.jpg" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechat.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/cn/OW-OD/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">OW Object Detector</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/cn/EfficientNet/"><span class="level-item">EfficientNet</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://aikenh.cn/cn/Attention/';
            this.page.identifier = 'cn/Attention/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'my-tech-blog-3' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/title.jpg" alt="AikenH"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">AikenH</p><p class="is-size-6 is-block">Future Full-Stack Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ShenZhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">131</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">98</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/AikenH" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="ZhiHu" href="https://www.zhihu.com/people/Aiken-h"><i class="fab fa-zhihu"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/1788200627"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Steam" href="https://steamcommunity.com/id/AikenH/"><i class="fab fa-steam"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#What’s-Attention-In-Deep-Learning"><span class="level-left"><span class="level-item">1</span><span class="level-item">What’s Attention In Deep Learning</span></span></a></li><li><a class="level is-mobile" href="#What’s-Wrong-with-Seq2Seq-Model"><span class="level-left"><span class="level-item">2</span><span class="level-item">What’s Wrong with Seq2Seq Model</span></span></a></li><li><a class="level is-mobile" href="#Born-for-Translation"><span class="level-left"><span class="level-item">3</span><span class="level-item">Born for Translation</span></span></a></li><li><a class="level is-mobile" href="#A-Family-of-Attention-Mechanism"><span class="level-left"><span class="level-item">4</span><span class="level-item">A Family of Attention Mechanism</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Summary"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Summary</span></span></a></li><li><a class="level is-mobile" href="#Self-Attention"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Self-Attention</span></span></a></li><li><a class="level is-mobile" href="#Soft-vs-Hard-Attention"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Soft vs Hard Attention</span></span></a></li><li><a class="level is-mobile" href="#Global-vs-Loacal-Attention"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">Global vs Loacal Attention</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Neural-Turing-Machines"><span class="level-left"><span class="level-item">5</span><span class="level-item">Neural Turing Machines</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Attention-Mechanisms"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">Attention Mechanisms</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Pointer-Network"><span class="level-left"><span class="level-item">6</span><span class="level-item">Pointer Network</span></span></a></li><li><a class="level is-mobile" href="#Transformer-Introduction"><span class="level-left"><span class="level-item">7</span><span class="level-item">Transformer Introduction</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Key-Value-and-Query"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">Key,Value and Query</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Encoder-Decoder-and-Taxonomy-of-Attention"><span class="level-left"><span class="level-item">8</span><span class="level-item">Encoder-Decoder and Taxonomy of Attention</span></span></a></li><li><a class="level is-mobile" href="#Transformer-and-Self-Attention"><span class="level-left"><span class="level-item">9</span><span class="level-item">Transformer and Self-Attention</span></span></a></li><li><a class="level is-mobile" href="#Reference"><span class="level-left"><span class="level-item">10</span><span class="level-item">Reference</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/cn/deploy_server_byipv6_02_nginx/"><img src="/img/header_img/lml_bg11.jpg" alt="使用Ipv6部署服务02 Nginx和Https"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-06T12:49:16.000Z">2023-11-06</time></p><p class="title"><a href="/cn/deploy_server_byipv6_02_nginx/">使用Ipv6部署服务02 Nginx和Https</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/Windows%E7%AB%AF%E5%8F%A3%E5%BC%82%E5%B8%B8%E5%8D%A0%E7%94%A8/"><img src="/img/header_img/lml_bg9.jpg" alt="Windows端口异常占用"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-05T15:46:54.000Z">2023-11-05</time></p><p class="title"><a href="/cn/Windows%E7%AB%AF%E5%8F%A3%E5%BC%82%E5%B8%B8%E5%8D%A0%E7%94%A8/">Windows端口异常占用</a></p><p class="categories"><a href="/categories/Windows/">Windows</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/deploy_server_byipv6/"><img src="/img/header_img/lml_bg10.jpg" alt="使用Ipv6部署服务01 IPV6开启和设置"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-05T11:23:17.000Z">2023-11-05</time></p><p class="title"><a href="/cn/deploy_server_byipv6/">使用Ipv6部署服务01 IPV6开启和设置</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/Flashcard_template/"><img src="/img/header_img/lml_bg35.jpg" alt="Obsidian使用 Spaced Repetition 制作闪念卡片"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-10-27T16:39:59.000Z">2023-10-28</time></p><p class="title"><a href="/cn/Flashcard_template/">Obsidian使用 Spaced Repetition 制作闪念卡片</a></p><p class="categories"><a href="/categories/Editor/">Editor</a> / <a href="/categories/Editor/Obsidian/">Obsidian</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/vsocde_regexp/"><img src="/img/header_img/lml_bg31.jpg" alt="VsCode&#039;s RegExp Catch 正则捕获"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-10-19T08:53:03.000Z">2023-10-19</time></p><p class="title"><a href="/cn/vsocde_regexp/">VsCode&#039;s RegExp Catch 正则捕获</a></p><p class="categories"><a href="/categories/Editor/">Editor</a> / <a href="/categories/Editor/Vscode/">Vscode</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Aiken&#039;s Blog</a><p class="is-size-7"><span>&copy; 2023 AikenH</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_pv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span> and <span id="busuanzi_container2_site_uv"><span id="busuanzi_value_site_pv">0</span>&nbsp;visits</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>