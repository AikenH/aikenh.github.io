<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: Machine Learning - AikenH Blogs</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Aiken Hong"><meta name="msapplication-TileImage" content="/img/pokemon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Aiken Hong"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Development Documentation"><meta property="og:type" content="blog"><meta property="og:title" content="AikenH Blogs"><meta property="og:url" content="http://aikenh.cn/"><meta property="og:site_name" content="AikenH Blogs"><meta property="og:description" content="Development Documentation"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://aikenh.cn/img/og_image.png"><meta property="article:author" content="AikenH"><meta property="article:tag" content="AikenH,Aiken,blog,Blog"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://aikenh.cn/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://aikenh.cn"},"headline":"AikenH Blogs","image":["http://aikenh.cn/img/og_image.png"],"author":{"@type":"Person","name":"AikenH"},"publisher":{"@type":"Organization","name":"AikenH Blogs","logo":{"@type":"ImageObject","url":{"text":"Aiken's Blog"}}},"description":"Development Documentation"}</script><link rel="icon" href="/img/pokemon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css" title="default"><link rel="alternate stylesheet" href="/css/cyberpunk.css" title="cyberpunk"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="AikenH Blogs" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Aiken&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-lightbulb" id="night-icon"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Machine Learning</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/FineTune/"><img class="fill" src="/img/header_img/lml_bg37.jpg" alt="Fine Tuning"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/FineTune/"><i class="fas fa-angle-double-right"></i>Fine Tuning</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-02-08T06:31:37.000Z" title="2022-02-08T06:31:37.000Z">2022-02-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 847 words)</span></div></div><div class="content"><p>@Langs: python, torch<br>@reference: d2l-pytorch，<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">transfer_torch</a></p>
<p>This Note focus on the code part.<br>模型微调和模型预训练，在Pytorch中的使用方式对比汇总。</p>
<h2 id="How-to-Design-the-Fine-Tune"><a href="#How-to-Design-the-Fine-Tune" class="headerlink" title="How to Design the Fine Tune"></a>How to Design the Fine Tune</h2><p>这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211205143153.png" alt="WorkFlow"></p>
<p>基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。</p>
<p>在Transfer任务中，有几种不同的调整方式：</p>
<ul>
<li>固定Bakcbone，只训练Classifier</li>
<li>同步微调网络</li>
<li>区分学习率，微调Backbone，训练Classifirer</li>
</ul>
<p>为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。</p>
<h2 id="Code-Part"><a href="#Code-Part" class="headerlink" title="Code Part"></a>Code Part</h2><h3 id="不同lr设置"><a href="#不同lr设置" class="headerlink" title="不同lr设置"></a>不同lr设置</h3><p><strong>微调Backbone，训练Classifier</strong>作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch, </a><a class="link-muted" rel="tag" href="/tags/Fine-Tune/">Fine-Tune </a></div><a class="article-more button is-small is-size-7" href="/cn/FineTune/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IL-Collection/"><img class="fill" src="/img/header_img/lml_bg9.jpg" alt="IL Collection"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IL-Collection/"><i class="fas fa-angle-double-right"></i>IL Collection</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-01-03T17:38:04.000Z" title="2022-01-03T17:38:04.000Z">2022-01-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:08:31.637Z" title="2023/10/31 08:08:31">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">29 minutes read (About 4422 words)</span></div></div><div class="content"><p>@AikenHong 2022</p>
<p>[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.</p>
<p>In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure.<br>在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_36474809/article/details/116176371">DER</a></li>
<li>SPPR 没有 get 到方法到底是怎么做的</li>
</ul>
<h2 id="Introduction-👿"><a href="#Introduction-👿" class="headerlink" title="Introduction 👿"></a>Introduction 👿</h2><p>在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。</p>
<p>Incremental 的基本过程可以表示如下<sub>[4]</sub>：<br><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/20220106101003.png" alt="dsa"></p>
<p>我们将模型可以划分为以下的两个部分<sub>[1]</sub>：backbone 和 classifier<br><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220105213925.png" alt="split"></p>
<p>从 LWF 中我们可以知道经典的 Paradigm，主要有下面的三种来对$\theta _S$ 和$\theta_o$来进行更新：</p>
<ul>
<li>仅重新训练分类器：仅更新$\theta_o$</li>
<li>微调特征提取器，重新训练分类器</li>
<li>联合训练</li>
</ul>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106111235.png" alt=""></p>
<h2 id="基于蒸馏架构的方法"><a href="#基于蒸馏架构的方法" class="headerlink" title="基于蒸馏架构的方法"></a>基于蒸馏架构的方法</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Incremental-Learning/">Incremental Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/IL-Collection/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IL-WYZ/"><img class="fill" src="/img/header_img/lml_bg29.jpg" alt="WYZ-IL-Collection"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IL-WYZ/"><i class="fas fa-angle-double-right"></i>WYZ-IL-Collection</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-01-03T02:41:56.000Z" title="2022-01-03T02:41:56.000Z">2022-01-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">7 minutes read (About 1123 words)</span></div></div><div class="content"><p>: hammer: 王耀智</p>
<h2 id="Regularization-系列方法"><a href="#Regularization-系列方法" class="headerlink" title="Regularization 系列方法"></a>Regularization 系列方法</h2><p>这类方法旨在添加一些正则化损失来解决 <code>catastrophic forgetting</code> 的问题。</p>
<h3 id="Weight-Regularization"><a href="#Weight-Regularization" class="headerlink" title="Weight Regularization"></a>Weight Regularization</h3><p>这类方法一般是对网络中每个参数的重要性进行评估，根据每个参数的重要性和梯度信息更新参数。</p>
<p>典型的文章为 <a target="_blank" rel="noopener" href="https://www.pnas.org/content/pnas/114/13/3521.full.pdf">EWC</a> .</p>
<blockquote>
<p>PS: 这类文章我也没有读过。</p>
</blockquote>
<h3 id="Data-Regularization"><a href="#Data-Regularization" class="headerlink" title="Data Regularization"></a>Data Regularization</h3><p>这类方法专注于记住特征表示，通常是结合 Hinton 的知识蒸馏损失函数使得模型记住旧类别的知识，解决 catastrophic forgetting。</p>
<p>推荐以下几篇文章：</p>
<ul>
<li><code>LwF</code>(Learning without forgetting)，这篇文章在我看来是增量学习的开山之作，第一次给增量学习找到了一个比较好的方向，也是第一次将知识蒸馏应用到增量学习上；</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.13513">PODNet CVPR2020</a> ，这篇文章最大的贡献在我看来是设计了一个全新的蒸馏损失函数，最终结果也是达到了当时的sota，甚至目前也是几个榜单的sota。</li>
</ul>
<h2 id="Rehearsal-系列方法"><a href="#Rehearsal-系列方法" class="headerlink" title="Rehearsal 系列方法"></a>Rehearsal 系列方法</h2><p>这类方法主要的想法是使用一些旧类别的数据，在新类别到来时使用新旧数据一起训练模型，根据旧类别数据的真假分为以下两种方法。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Incremental-Learning/">Incremental Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/IL-WYZ/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/LT-Collection/"><img class="fill" src="/img/header_img/lml_bg27.jpg" alt="LT Collection"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/LT-Collection/"><i class="fas fa-angle-double-right"></i>LT Collection</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-22T06:36:16.000Z" title="2021-12-22T06:36:16.000Z">2021-12-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:11:54.338Z" title="2023/10/31 08:11:54">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">26 minutes read (About 3848 words)</span></div></div><div class="content"><h1 id="LT-Collections"><a href="#LT-Collections" class="headerlink" title="LT-Collections"></a>LT-Collections</h1><p>@AikenHong 2021</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mitming/OpenLT">Code of must of those methods</a><br>We will analysis those tricks on LT situation, and Analysis why it works.<br>在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。</p>
<p>其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png" alt="LT"><br>通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合</p>
<p>首先介绍 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/416315017">bag of tricks</a> 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick</p>
<p>经过该文实验总结，Trick组合应该是<sub>[1]`</sub>：</p>
<ul>
<li>在前几个epoch应用input mixup数据增强，然后后面fine-tuning;</li>
<li>(基于CAM的)重采样来重新训练分类器;</li>
</ul>
<p>实际上就是MixUp + Two-Stage的策略，后续对<strong>Mix-up</strong>这个策略带来的作用要进行补充了解一下</p>
<h2 id="Rebalance"><a href="#Rebalance" class="headerlink" title="Rebalance"></a>Rebalance</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Long-Tailed-Learning/">Long-Tailed Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/LT-Collection/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Loss-NCE/"><img class="fill" src="/img/header_img/lml_bg35.jpg" alt="Loss-NCE"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Loss-NCE/"><i class="fas fa-angle-double-right"></i>Loss-NCE</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-22T05:39:55.000Z" title="2021-12-22T05:39:55.000Z">2021-12-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">17 minutes read (About 2506 words)</span></div></div><div class="content"><p>@AikenHong 2021</p>
<p>Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples.<br>该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。</p>
<h2 id="What’s-NCE-Loss"><a href="#What’s-NCE-Loss" class="headerlink" title="What’s NCE Loss"></a>What’s NCE Loss</h2><p>在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）</p>
<p>首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上<code>j==gt</code>的情况下外层+log也就是ceLoss，也就是 $logSoftmax$</p>
<script type="math/tex; mode=display">
S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}</script><p>然后看infoNCE，基础的对比学习损失可以写成：</p>
<script type="math/tex; mode=display">
L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]</script><p>其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带$T$的NCE，即InforNCE.</p>
<p>分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。</p>
<p>从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。</p>
<blockquote>
<p>但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。</p>
</blockquote>
<h2 id="How-it-Works"><a href="#How-it-Works" class="headerlink" title="How it Works"></a>How it Works</h2><p>NCE的思想是<strong>拉近相似的样本，推开不相近的样本</strong>，从而学习到一个好的<strong>语义表示空间</strong>，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。</p>
<p>考虑之前人脸匹配的研究，使用 “Alignment and Uniformity on the Hypersphere”中的Alignment and Uniformity，就是一个更好理解他的角度<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Loss/">Loss </a></div><a class="article-more button is-small is-size-7" href="/cn/Loss-NCE/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Loss-SmoothSharpen/"><img class="fill" src="/img/header_img/lml_bg37.jpg" alt="Loss-Smooth(Sharpen)"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Loss-SmoothSharpen/"><i class="fas fa-angle-double-right"></i>Loss-Smooth(Sharpen)</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-16T19:35:27.000Z" title="2021-12-16T19:35:27.000Z">2021-12-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:11:42.791Z" title="2023/10/31 08:11:42">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 974 words)</span></div></div><div class="content"><p>@AikenHong 2021<br>@topic</p>
<ul>
<li>smooth label (inception v2)</li>
<li>when does label smoothing help (nips 2019) </li>
<li>sharpen in semi-supervised in the future </li>
<li><a target="_blank" rel="noopener" href="https://github.com/seominseok0429/label-smoothing-visualization-pytorch?utm_source=catalyzex.com">offical code github</a></li>
</ul>
<p>不是一个通用的方法，在很多的任务上反而会导致掉点的现象，可以简单分析一下，汲取一下思想和Sharpen做对比，在这篇文章中，我们可以结合之前的人脸对比损失来进行分析。</p>
<h2 id="What’s-the-smooth-label"><a href="#What’s-the-smooth-label" class="headerlink" title="What’s the smooth label"></a>What’s the smooth label</h2><p>首先介绍在图像分类任务中对logits和Hard label做ce得到我们的损失，可以表现为如下的形式：</p>
<script type="math/tex; mode=display">
Loss = -\sum^{K}_{i=1}p_i \log(q_i)</script><p>由于我们的标签是一个hard label，实际上可以转化成一个one-hot，即</p>
<script type="math/tex; mode=display">
\begin{equation}
p_i = \left\{
\begin{array}{c1}
1 & i==gt \\
0 & i!=gt \\
\end{array} \right.
\end{equation}</script><p>而soft label实际上做的是将 1的位置变为$1-\alpha$，其他位置设置为$\alpha/(K-1)$，然后再去求CE，</p>
<p>Hinton论文中给出该损失对特征分布的作用测试图：<br><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211216194040.png" alt=""></p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Loss/">Loss </a></div><a class="article-more button is-small is-size-7" href="/cn/Loss-SmoothSharpen/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/NerualNetworkTraining/"><img class="fill" src="/img/header_img/lml_bg37.jpg" alt="Training Strategy"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/NerualNetworkTraining/"><i class="fas fa-angle-double-right"></i>Training Strategy</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-16T00:34:44.000Z" title="2021-12-16T00:34:44.000Z">2021-12-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">27 minutes read (About 4090 words)</span></div></div><div class="content"><p>@Aiken 2020，</p>
<p>主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。</p>
<p>参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。</p>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p><a target="_blank" rel="noopener" href="https://wizardforcel.gitbooks.io/learn-dl-with-pytorch-liaoxingyu/content/">Some Material</a><br>实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：</p>
<p>Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。</p>
<p>但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。</p>
<h2 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h2><p>$\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，</p>
<p>==Basic==</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>学习率大</th>
<th>学习率小</th>
</tr>
</thead>
<tbody>
<tr>
<td>学习速度</td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td>使用情景</td>
<td>刚开始训练时</td>
<td>一定的次数过后</td>
</tr>
<tr>
<td>副作用</td>
<td>1. Loss爆炸 2.振荡</td>
<td>1.过拟合 2.收敛速度慢</td>
</tr>
</tbody>
</table>
</div>
<h3 id="学习率的基本设置"><a href="#学习率的基本设置" class="headerlink" title="学习率的基本设置"></a>学习率的基本设置</h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch, </a><a class="link-muted" rel="tag" href="/tags/Acceleration/">Acceleration </a></div><a class="article-more button is-small is-size-7" href="/cn/NerualNetworkTraining/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Loss-WhyZero/"><img class="fill" src="/img/header_img/lml_bg27.jpg" alt="Loss-WhyZero"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Loss-WhyZero/"><i class="fas fa-angle-double-right"></i>Loss-WhyZero</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-10T00:24:46.000Z" title="2021-12-10T00:24:46.000Z">2021-12-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 776 words)</span></div></div><div class="content"><h1 id="Loss-Why-Zero-Loss？"><a href="#Loss-Why-Zero-Loss？" class="headerlink" title="Loss :Why Zero Loss？"></a>Loss :Why Zero Loss？</h1><p>@Comments: ICML2020 《Do We Need Zero Training Loss After Achieving Zero Training Error》</p>
<p>@Noteby：AikenHong2021</p>
<p>如何解决训练损失下降，但是验证损失上升的问题（过拟合like）的问题，该文章实际上可以作为我们损失设计中的一个trick，只需要简单的一行代码，来提升代码的泛化能力；</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211026211602.png" alt="img"></p>
<p>这张图体现了本文的灵魂（思路），主要体现在我们在算法趋于稳定后继续训练可能验证损失会反而上升；</p>
<p>所以本文提出了一种flooding方法，当我们training loss 大于阈值的时候我们使其正常下降，当低于阈值的时候，flooding的设计会反过来使得梯度上升，让训练损失保持在flooding附近，让模型持续进行random walk，希望模型最终能优化到一个平坦的损失区域，这样发现test loss进一步的进行下降。</p>
<p>理解：</p>
<p>当我们的训练损失低到一定的程度，然后随着lr的下降，模型会很难跳出当前的极小值，这种情况下我们的泛化能力也会被限制住，采用这种方法在牺牲测试精度的同时能提升算法的泛化能力。</p>
<p>损失公式表示如下</p>
<script type="math/tex; mode=display">
\widetilde{J}(\theta) = |J(\theta) - b| +b</script><p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211027104636.jpg" alt="v2-084a8f00d7349a94540fc7ad3a9433b0_r"></p>
<p>具体的代码表示只需要添加一层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">b = the flood num <br>new_loss = (loss - b).<span class="hljs-built_in">abs</span>() + b<br>optimizer.zero_grad()<br>new_loss.backward()<br>optimizer.step()<br></code></pre></td></tr></table></figure></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Loss/">Loss </a></div><a class="article-more button is-small is-size-7" href="/cn/Loss-WhyZero/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/UniFramework/"><img class="fill" src="/img/header_img/lml_bg16.jpg" alt="UniFramework 01"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/UniFramework/"><i class="fas fa-angle-double-right"></i>UniFramework 01</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-12-03T17:43:30.000Z" title="2021-12-03T17:43:30.000Z">2021-12-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:28:20.614Z" title="2023/10/31 08:28:20">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">30 minutes read (About 4430 words)</span></div></div><div class="content">Here's something encrypted, password is required to continue reading.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/UniFramework/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/FSL-Collection/"><img class="fill" src="/img/header_img/lml_bg28.jpg" alt="Survey for Few-Shot Learning"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/FSL-Collection/"><i class="fas fa-angle-double-right"></i>Survey for Few-Shot Learning</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:06:15.654Z" title="2023/10/31 08:06:15">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">43 minutes read (About 6448 words)</span></div></div><div class="content"><p>@aikenhong 2020<br>@h.aiken.970@gmail.com</p>
<p>另一个综述文章：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/61215293">https://zhuanlan.zhihu.com/p/61215293</a><br>对该文中一些内容有一些补充，可以看看</p>
<p>FSL简介：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xhw205/article/details/79491649">https://blog.csdn.net/xhw205/article/details/79491649</a></p>
<p>GCN用于FSL：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36022260/article/details/93753532">https://blog.csdn.net/qq_36022260/article/details/93753532</a></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>FSL的根本目的就是弥合人工智能和人类之间的鸿沟，从少量带有监督信息的示例中学习。像人类一样有很高的泛化能力。这也能解决在实际应用场景中，数据难以收集或者大型数据难以建立的情景。</p>
<p>FSL的<strong>核心问题</strong>是：经验风险最小化器不可靠；那么如何<strong>使用先验知识</strong>去解决这个问题？</p>
<p>三个主要的角度：</p>
<ol>
<li>数据：使用先验知识增强数据的监督经验</li>
<li>模型：使用先验知识来降低假设空间</li>
<li>算法：使用先验知识来改变搜索最佳假设（来进行搜索？)</li>
</ol>
<p>现阶段针对FSL提出的一些相关的机器学习方法：<br><code>meta-learning;</code> <code>embedding learning;</code>  <code>generative modeling etc.</code></p>
<p><strong>本文的主要工作：</strong><br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/FSL/">FSL </a></div><a class="article-more button is-small is-size-7" href="/cn/FSL-Collection/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/FSL%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/"><img class="fill" src="/img/header_img/lml_bg38.jpg" alt="FSL前期调研"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/FSL%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/"><i class="fas fa-angle-double-right"></i>FSL前期调研</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:06:43.838Z" title="2023/10/31 08:06:43">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">21 minutes read (About 3220 words)</span></div></div><div class="content">Here's something encrypted, password is required to continue reading.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/FSL/">FSL </a></div><a class="article-more button is-small is-size-7" href="/cn/FSL%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/IL-MgSvF/"><img class="fill" src="/img/header_img/lml_bg3.jpg" alt="IL-MgSvF"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/IL-MgSvF/"><i class="fas fa-angle-double-right"></i>IL-MgSvF</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">8 minutes read (About 1165 words)</span></div></div><div class="content"><p>@Author &amp; Paper：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.15524.pdf">Arxiv</a><br>@Note：Aikenhong 2021/11/12</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/cp_oldy/article/details/111714896">Other’s Note 1 </a></p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><strong>旧知识的缓慢忘记和新知识的快速适应的困境</strong>：主要探讨Incremental中的Old和New的相互牵制和适应的问题，</p>
<p>旧知识的缓慢遗忘会导致对新任务的欠拟合，而快速适应会导致灾难性的遗忘，如何对这两种策略之间进行权衡，是一个重要的问题。</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211112114701.png" alt="image-20211112110043089"></p>
<p><strong>多尺度混合</strong>的解决这个问题：</p>
<ul>
<li>Intra-space： 新类别的特征在同一个特征空间中</li>
<li>inter-saoce：新旧类别的特征在不同的特征空间中</li>
</ul>
<p>本文提出的<strong>多粒度策略</strong>：</p>
<ol>
<li>提出了一种频率感知的正则化操作，加速空间内的增量学习能力</li>
<li>新的特征空间组合操作，提升空间间的学习性能</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Incremental-Learning/">Incremental Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/IL-MgSvF/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/SSL-MoCov3/"><img class="fill" src="/img/header_img/lml_bg4.jpg" alt="SSL-MoCov3"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/SSL-MoCov3/"><i class="fas fa-angle-double-right"></i>SSL-MoCov3</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-29T05:12:05.000Z" title="2021-11-29T05:12:05.000Z">2021-11-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">a minute read (About 162 words)</span></div></div><div class="content"><p>@Aiken 2021 </p>
<p>恺明大神对自监督学习+transformer的实证研究，针对Transformer再自监督学习学习框架中的训练不稳定问题提出了<strong>Random Patch Projection</strong>的解决方案。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/waqkJkwqxU-7utfNnwr2Gg">Article</a>；<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.02057">Paper</a>；</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>ViT的方法在自监督学习的任务中，精度下降的主要原因是由于算法的不稳定性，容易陷入局部的最优值，本文主要聚焦于<strong>采用视觉领域的自监督框架进行Transformer的训练</strong>，CNN的训练方法已经是一个比较明确约定俗称的方法，而Transformer的训练架构实际上还没有被完全的构建。</p>
</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/DataAugmentation/"><img class="fill" src="/img/header_img/lml_bg12.jpg" alt="Data Augmentation"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/DataAugmentation/"><i class="fas fa-angle-double-right"></i>Data Augmentation</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T22:24:20.000Z" title="2021-11-27T22:24:20.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">12 minutes read (About 1760 words)</span></div></div><div class="content"><p>intergrate with those augmentation method.</p>
<p>this doc will</p>
<ul>
<li>Record those theory and the effect after transformation</li>
<li>Show the codes for ez use</li>
</ul>
<p>And the complete <code>.py</code> will be intergrate in my classification pipeline</p>
<p><strong>reference</strong> below:arrow_down_small:, if use them,start it for respect for his work.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/aleju/imgaug#documentation">aleju/imgaug</a></li>
<li>:star:<a target="_blank" rel="noopener" href="https://github.com/albumentations-team/albumentations">albumentations-team/albumentations: </a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-and-torch-tensor">torchvision</a></li>
<li><a target="_blank" rel="noopener" href="https://pillow.readthedocs.io/en/stable/reference/ImageEnhance.html">PIL/ImageEnhance CCBS</a></li>
<li>opencv</li>
</ul>
<h2 id="Principle"><a href="#Principle" class="headerlink" title="Principle"></a>Principle</h2><p><strong>Principle 1</strong> of coding: Don’t reinvent the wheel unless it’s needed</p>
<ul>
<li>具体而言，仅在函数的拓展性较差，无法对其定制化，满足我们的日常需求的时候，我们会自行编写函数从而满足我们的需求，否则我们直接引用已知的库，提升我们的实现效率。</li>
</ul></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Augmentation/">Augmentation, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch </a></div><a class="article-more button is-small is-size-7" href="/cn/DataAugmentation/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MLFlow/"><img class="fill" src="/img/header_img/lml_bg38.jpg" alt="MLFlow"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MLFlow/"><i class="fas fa-angle-double-right"></i>MLFlow</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T22:24:19.000Z" title="2021-11-27T22:24:19.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">3 minutes read (About 397 words)</span></div></div><div class="content"><h1 id="MLFlow-机器学习系统的使用"><a href="#MLFlow-机器学习系统的使用" class="headerlink" title="MLFlow 机器学习系统的使用"></a>MLFlow 机器学习系统的使用</h1><p>@Aiken 2020</p>
<p><em>基于Python开发的DAG数据工作流系统，面向机器学习，支持Spark并行环境和K8S容器集群；</em></p>
<p>MLFlow主要解决了三个问题，也就是三个我们可能会需要使用的功能：</p>
<ol>
<li><strong>Tracking</strong>：跟踪实验训练结果，记录算法参数，模型结果和运行效果等等；</li>
<li>Projects：对所有的算法项目有一套标准的projects概念，记录下代码版本，参数和运行环境这些东西，并且projects是可以拟合所有的算法框架的；</li>
<li>Models：解决的是打包和部署模型的这样一个行为，提供json接口给后续的flsk框架等等进行使用</li>
</ol>
<h2 id="基本部署"><a href="#基本部署" class="headerlink" title="基本部署"></a>基本部署</h2><p>INSTALL：</p>
<p>DEPLOY：</p>
<h2 id="Tracking-实验版本跟踪"><a href="#Tracking-实验版本跟踪" class="headerlink" title="Tracking 实验版本跟踪"></a>Tracking 实验版本跟踪</h2><p><strong>Tracking</strong>为本次描述的重点，来做一个训练过程中的版本管理，记录每一次训练的参数和变量信息等等，这样便于后续的恢复和实验信息的整理。便于统计和管理。使用的时候好像也是需要代码嵌入的部分，就是需要在代码中调用MLFlow的API。</p>
<p>但是在Tracking的时候有一个比较重要的点在于，这个方法和<code>Tensorboard</code>对原模型的参数的嵌入和Logging记录中<u>会不会产生冲突</u>，同时两个方法之间是不是有什么overlap；关键的问题：</p>
<ul>
<li>这两个API能不能进行混合使用</li>
<li>怎么统一和区分两个方法的应用情景</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/MLFlow/">MLFlow </a></div><a class="article-more button is-small is-size-7" href="/cn/MLFlow/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/"><img class="fill" src="/img/header_img/lml_bg34.jpg" alt="并行训练"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/"><i class="fas fa-angle-double-right"></i>并行训练</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-27T18:20:31.000Z" title="2021-11-27T18:20:31.000Z">2021-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 794 words)</span></div></div><div class="content"><p><a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2021/09/24/train-large-neural-networks.html">How to Train Really Large Models on Many GPUs? (lilianweng.github.io)</a></p>
<p>对于浮点运算，模型参数的存储和中间计算输出（梯度和优化器状态）的存储的在 GPU 内存上的大量需求使得我们需要并行化，下面我们参考一些常用的并行化范式：</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pytorch/">Pytorch </a></div><a class="article-more button is-small is-size-7" href="/cn/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MIM-V-simMIM/"><img class="fill" src="/img/header_img/lml_bg29.jpg" alt="MIM-V-simMIM"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MIM-V-simMIM/"><i class="fas fa-angle-double-right"></i>MIM-V-simMIM</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-22T22:38:19.000Z" title="2021-11-22T22:38:19.000Z">2021-11-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">9 minutes read (About 1339 words)</span></div></div><div class="content"><p>@Author： MSRA Zhenda Xie<br>@Source：<a href="arxiv.org/abs/2111.09886">Arxiv</a>， <a target="_blank" rel="noopener" href="https://github.com/microsoft/SimMIM">Code TBP</a>，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/4YVYM9lPYghtZFhyOGnERw">Blog_CVer</a><br>@Read：AikenHong 2021.11.22</p>
<p>“What I cannot create, I do not understand.” — Richard Feynman</p>
<h2 id="Intro-amp-Simple-Conclusion"><a href="#Intro-amp-Simple-Conclusion" class="headerlink" title="Intro &amp; Simple Conclusion"></a>Intro &amp; Simple Conclusion</h2><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>继MAE和iBoT之后，MSRA也提出了一个图像掩码建模的新框架，SimMIM，该方法简化了最近这些提出的方法，不需要特殊设计，作者也验证了不需要那些特殊设计就已经能让模型展现出优秀的学习能力</p>
<ul>
<li>采用中等大小的掩码块（32），对输入图像进行随机掩码，能使其成为强大的代理任务（pretext task）</li>
<li>直接回归预测原始像素的RGB值的效果并不比复杂设计的Patch分类方法差</li>
<li>Projector Head可以是轻量的Linear Layer，效果并不一定比MLP（多层）的差</li>
</ul>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>通过这种MIM方法可以实现在大量无标注的数据上得到一个表征能力up的通用特征模型，这种方式的backbone可以广泛的应用到图像上的各种子任务中（按照NLP）的经验来说，而为了类似的方式在图像上的大放异彩，我们首先需要分析Vision和Language的不同</p>
<ol>
<li><strong>图像有更强的局部关系</strong>：相互靠近的像素是高度相关和近似的，我们可以通过简单的copy padding复制一部分缺失</li>
<li><strong>视觉信号是原始，低层次的，而文本分词是高级概念</strong>：对低层次信号的预测是否对高层次的视觉识别任务有用呢？</li>
<li><strong>视觉信号是连续的，而文本的分词是离散的</strong>： 如何基于分类的掩码语言建模方法来处理连续的视觉信号</li>
</ol>
<h2 id="Theoretical-Design"><a href="#Theoretical-Design" class="headerlink" title="Theoretical Design"></a>Theoretical Design</h2><p><strong>掩码选择</strong>：同样的掩码的策略还是基于Patch进行的，对于掩码的设计来说，太大的掩码快或者太密集的掩码快，可能会导致找不到附近的像素来预测，实验证明32是一个具有竞争力的size，和文本任务的信息冗余程度不同也带来了覆盖比的选择，NLP通常是0.15，而在V中，32size可以支持0.1-0.7的覆盖率。</p>
<p><strong>任务选择</strong>：使用原始像素的回归任务，因为回归任务和具有有序性的视觉信号的连续性很好的吻合。</p>
<p><strong>预测头选择</strong>：使用轻量的预测头如（linear），迁移性能与繁琐的预测头相似或者略好，同时训练上更加的块。虽<strong>然较大的头或更高的分辨率通常会导致更强的生成能力，但这种更强的能力不一定有利于下游的微调任务</strong>。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/MIM-V-simMIM/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Transformer/"><img class="fill" src="/img/header_img/lml_bg10.jpg" alt="Transformer"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Transformer/"><i class="fas fa-angle-double-right"></i>Transformer</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-22T22:38:19.000Z" title="2021-11-22T22:38:19.000Z">2021-11-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">4 minutes read (About 636 words)</span></div></div><div class="content"><p>@aikenhong 2021   </p>
<p>References For Transformer:</p>
<ol>
<li>NLP <a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html">The Transformer Family (lilianweng.github.io)</a></li>
<li>VIT <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MjM5ODExNDA2MA==&amp;mid=2449941486&amp;idx=1&amp;sn=336a47a31f4b4ff0f6cd8e2fc3cb184a&amp;chksm=b13c258d864bac9b32d10ec36a058d77cc7cf90e066e76ae476fd2fde1b54256cd608a559bb6&amp;mpshare=1&amp;scene=23&amp;srcid=1101rcBaNzO4pu00PCPsJOAl&amp;sharer_sharetime=1635744838591&amp;sharer_shareid=ec299f1c891fc72cd699f8eaeb8a0cd5#rd">Transformer眼中世界 VS CNN眼中世界</a></li>
<li>李沐 NLP <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1pu411o7BE?spm_id_from=333.999.0.0">Transformer论文精读</a></li>
<li>Suveys <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&amp;mid=2247514162&amp;idx=2&amp;sn=d094eecbfd91ca1e478c41e29f2b98d5&amp;scene=21#wechat_redirect">cver1</a>， <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&amp;mid=2247514982&amp;idx=2&amp;sn=7e38021234b7ab5455429e4485128efd&amp;chksm=f9a1c9e9ced640ff045d1c4fe9d4e98a785602d980b25df4fa18477dd2b4b829ed4fc3fd028f&amp;scene=21#wechat_redirect">cver2</a>，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/_th7rXfZDuSu2xo7gdPp0w">cver3</a></li>
</ol>
<p>This blog will divided into several part : lil’s blog, the survey for ViT, we using those article to help us understand the transformer.</p>
<p>综述我们以最新的一篇为准进行阅读，其他的可能后续进行查缺补漏把，如无必要，勿增烦恼。</p>
<h2 id="Intro导言"><a href="#Intro导言" class="headerlink" title="Intro导言"></a>Intro导言</h2><p>主要参考文章2来进行我们简单的导入</p>
<h3 id="基本问题"><a href="#基本问题" class="headerlink" title="基本问题"></a>基本问题</h3><p>Transformer原本是NLP中的重要模型, 作为LSTM的后继者, 用于处理Seq2Seq的数据类型和情景, 若是要将Transformer运用到Vision的领域中, 首要的问题就是如何:</p>
<p><strong>将Image作为序列化的Token输入Transform中</strong> , 而达成这个目的主要有三种典型的方法:</p>
<ul>
<li>像素点作为token,</li>
<li>使用VAE离散化图片作为token再输入</li>
<li>ViT: 将图片切为一个个<code>Patch</code>在经过线性的<code>projector</code>之后组成一个<code>embedding</code>表示进行交互</li>
</ul>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211120010516" alt="图片"></p>
<h3 id="CNN的异同分析"><a href="#CNN的异同分析" class="headerlink" title="CNN的异同分析"></a>CNN的异同分析</h3><p>差异分析和计算主要靠CKA向量相似度计算来计算模型和表征之间的差异，这里的理论分析暂且不赘述，后续有需求的话可参考论文Similarity of neural network representations revisited或当前文章.<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/Transformer/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MIM-V-iBOT/"><img class="fill" src="/img/header_img/lml_bg15.jpg" alt="MIM-V-iBOT"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MIM-V-iBOT/"><i class="fas fa-angle-double-right"></i>MIM-V-iBOT</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-17T22:35:52.000Z" title="2021-11-17T22:35:52.000Z">2021-11-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 823 words)</span></div></div><div class="content"><p>@Read: AikenHong 2021</p>
<p>@Author: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.07832">https://arxiv.org/abs/2111.07832</a></p>
<p>@解读：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/x4yEfg9eqW6x3Ehxm1HkRA">Machine Heart</a></p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>基于NLP中的MLM(Masked Language Model)的核心训练目标: 也就是遮住文本的一部分, 然后通过模型去预测和补全, 这一过程是模型学到泛化的特征, 使用这种方法来进行大规模的与训练范式.</p>
<p>在基本的思想上和MAE采用的是一样的设计, 但是本文中坐着认为visual tokenizer的设计才是其中的关键.</p>
<blockquote>
<p>不同于 NLP 中 tokenization 通过离线的词频分析即可将语料编码为含高语义的分词，图像 patch 是连续分布的且存在大量冗余的底层细节信息。而作者认为一个能够提取图像 patch 中高层语义的 tokenizer 可帮助模型避免学习到冗余的这些细节信息。作者认为视觉的 tokenizer 应该具备两个属性：（a）具备完整表征连续图像内容的能力；(b) 像 NLP 中的 tokenizer 一样具备高层语义。</p>
</blockquote>
<p>文中对tokenizer的设计为一个知识蒸馏的过程:</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211118151616.png" alt="image-20211118151613545"></p>
<p>文中使用这种在线tokenizer同时来监督这样的MIM过程, 也就是两部分协同学习, 能够较好的保证语义的同时并将图像内容转化为连续的特征分布, 具体的, tokenizer和目标网络狗狗想网络结构, 有移动平均来得到实际的tokenizer.</p>
<p>该形式近期在 DINO [3]中以自蒸馏被提出，并被用以针对同一张图片的两个不同视野在 [CLS] 标签上的优化：</p>
<script type="math/tex; mode=display">
L_{CLS} = - P_{\theta^`}^{[CLS]}(v)^T logP_{\theta}^{[CLS]}(\mu)</script><p>在该损失函数的基础上, MIM同样也是用这种自蒸馏的方式去优化, 其中在线tokenizer的参数为目标网络历史参数的平均.</p>
<script type="math/tex; mode=display">
L_{MIM} = - \sum_{i=1}^Nm_i *P_{\theta^`}^{patch}(\mu_i)^TlogP_{\theta}^{patch}(\hat{\mu}_i)</script><p>基于上述的这些训练目标，提出了一种自监督预训练框架iBOT， 同时优化两种损失函数。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/MIM-V-iBOT/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/MIM-V-MAE/"><img class="fill" src="/img/header_img/lml_bg43.jpg" alt="MIM-V-MAE"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/MIM-V-MAE/"><i class="fas fa-angle-double-right"></i>MIM-V-MAE</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-15T04:25:45.000Z" title="2021-11-15T04:25:45.000Z">2021-11-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">3 minutes read (About 504 words)</span></div></div><div class="content"><p>@Author：Facebook AI Research-Kaiming He<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/432663453">Kaiming-MAE</a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>总而言之这是一种大模型的训练方法, 通过在少量数据的基础上实现大模型的训练.</p>
<p>整体的架构上是参考了NLP中的AutoEncoder机制，将原图切分patch，用mask掩盖原图，通过少量可见的Patch进行Encoder后和Mask融合，再通过<strong>非对称</strong>的Decoder进行pixel的还原。</p>
<p>这种设计的有点在于mask的scala是可变的，同时这种mask能减少我们训练过程中对显存和计算复杂度的损耗，同时问题本身是一个比较复杂的问题，得以训练复杂的大模型，这种方式最终呈现的效果就是训练的效率高且效益好。</p>
<p>体现了自监督学习在这方面的优越性，同时这种方法得以实现也是由于ViT模型对于CNN模型的取代，才使得这种序列化切块的方式容易实现和验证。</p>
<p>这种方式在最终体现了自监督学习对于有监督与训练的优越性，使用这种方式能够更好的得到一个模型的通用表征。</p>
<p>在这里论文中也说明了和NLP的不同点以及这样的模型对于decoder的要求实际上是比NLP更高的</p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211115113546.png" alt="image-20211115113542074"></p>
<h2 id="experiment"><a href="#experiment" class="headerlink" title="experiment"></a>experiment</h2><p><strong>Masking</strong>：对于输入的图像进行均匀的切分并均匀的随机采样</p>
<p><strong>MAE encoder</strong>: 简单的ViT模型，对输入图像进行编码后和Mask进行混合得到一个完整的令牌集合，从而确保Decode能够得到对应的位置信息。</p>
<p><strong>MAE decoder</strong>：轻量级的架构，可以独立于编码器进行设计，我们使用更窄更浅的网络，计算量比编码器10%更小，这样能够更快的进行训练。解码器的最后一层是先行投影，输出的数量==补丁中像素值的数量，最后会resize层原图的维度。</p>
</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/OWL-survey/"><img class="fill" src="/img/header_img/lml_bg15.jpg" alt="OWL-survey"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/OWL-survey/"><i class="fas fa-angle-double-right"></i>OWL-survey</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-11-12T01:40:46.000Z" title="2021-11-12T01:40:46.000Z">2021-11-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">14 minutes read (About 2062 words)</span></div></div><div class="content"><p>@AikenHong2021 OWL</p>
<p>分析现有的OWL特点，和当前自己的研究做一个区分，也汲取一下别人的研究的要点，</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.07848.pdf">self-supervised feature improve open-world learning</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/374268236">arxiv</a> @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.03526.pdf">open-world semi-supervised learning</a></li>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.12906.pdf">open-world learning without labels</a></li>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.05609.pdf">unseen class discovery in open-world classification</a></li>
<li>arxiv @ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2109.06628.pdf">Open-World Active Learning with Stacking Ensemble for Self-Driving Cars</a></li>
<li><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3308558.3313644">www</a> @ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011150266/article/details/118242627">open-world learning and application to product classification</a></li>
<li>cvpr @ <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mancini_Open_World_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf">open world composition zero-shot learning</a> </li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.02603.pdf">cvpr</a> @ <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356272271">Towards Open World Object Detection</a></li>
<li><a href="[Large-Scale Long-Tailed Recognition in an Open World (thecvf.com">cvpr</a>](<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.pdf</a>)) @ <a target="_blank" rel="noopener" href="https://github.com/zhmiao/OpenLongTailRecognition-OLTR">Large-Scale Long-Tailed Recognition in an Open World</a></li>
</ol>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><p><strong>Mulit Open world Learning Definition</strong></p>
<p>拒绝未见过的类的实例，逐步学习新的类扩展现有模型</p>
<h3 id="zap-Large-Scale-Long-Tailed-Recognition-in-an-Open-World"><a href="#zap-Large-Scale-Long-Tailed-Recognition-in-an-Open-World" class="headerlink" title=":zap: Large-Scale Long-Tailed Recognition in an Open World"></a>:zap: Large-Scale Long-Tailed Recognition in an Open World</h3><p><a target="_blank" rel="noopener" href="https://liuziwei7.github.io/projects/LongTail.html">Large-Scale Long-Tailed Recognition in an Open World (liuziwei7.github.io)</a></p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV, </a><a class="link-muted" rel="tag" href="/tags/Open-World-Learning/">Open World Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/OWL-survey/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/SS_OD_SoftTeacher/"><img class="fill" src="/img/header_img/lml_bg24.jpg" alt="SS_OD_SoftTeacher"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/SS_OD_SoftTeacher/"><i class="fas fa-angle-double-right"></i>SS_OD_SoftTeacher</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-08T18:30:08.000Z" title="2021-10-08T18:30:08.000Z">2021-10-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">9 minutes read (About 1398 words)</span></div></div><div class="content"><p>@ Article: ICML from Microsoft &amp; Huazhong Keda<br>@ Code: <a target="_blank" rel="noopener" href="https://github.com/microsoft/SoftTeacher">Github</a><br>@ Noteby: Aikenhong<br>@ Time: 20210914</p>
<h2 id="Abstrast-and-Intro"><a href="#Abstrast-and-Intro" class="headerlink" title="Abstrast and Intro"></a>Abstrast and Intro</h2><p>in the session we will using describe the main idea of this article.</p>
<p>这篇文章的重点在于Soft Teacher，也就是用pseudo label做为弱标注，逐步提高伪标签的可靠性。</p>
<p>不同于多阶段的方法，端到端的方法再训练中逐步的提升伪标签的质量从而再去benifit目标检测的质量。<br>这样E2E的框架主要依赖于两部分技术:</p>
<ul>
<li>soft teacher: 每个未标记边界框的分类损失由教师网络产生的分类分数进行加权</li>
<li>box jitter 窗口抖动: 选择可靠的伪框来学习框回归</li>
</ul>
<p>在目标检测上获得SOTA的效果;</p>
<h3 id="Multi-Stage"><a href="#Multi-Stage" class="headerlink" title="Multi-Stage"></a>Multi-Stage</h3><p>在半监督的情况下，关注的主要是基于伪标签的方法，是目前的SOTA，以往的方法采用多阶段的方式。</p>
<ol>
<li>使用标记数据训练初始检测器</li>
<li>未标记数据的伪标记，同时基于伪标签进行重新训练</li>
</ol>
<p><strong>局限</strong>：初始少量标注的局限，初始的检测器的伪标签质量</p>
<h3 id="End-to-End"><a href="#End-to-End" class="headerlink" title="End to End"></a>End to End</h3><p><strong>Soft Teacher</strong>基本思路：对未标记的图像进行标记，然后通过标记的几个伪标签训练检测器.<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Semi-Supervised-Learning/">Semi-Supervised Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/SS_OD_SoftTeacher/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/StyleGAN/"><img class="fill" src="/img/header_img/lml_bg18.jpg" alt="StyleGAN"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/StyleGAN/"><i class="fas fa-angle-double-right"></i>StyleGAN</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-03T05:16:40.000Z" title="2021-10-03T05:16:40.000Z">2021-10-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 879 words)</span></div></div><div class="content"><h1 id="StyleGAN-V1"><a href="#StyleGAN-V1" class="headerlink" title="StyleGAN V1"></a>StyleGAN V1</h1><p>@AikenHong 2020 10.8</p>
<p>《A Style-Based Generator Architecture for Generative Adversarial Networks》</p>
<h2 id="Related-Work："><a href="#Related-Work：" class="headerlink" title="Related Work："></a>Related Work：</h2><p>继承的文献工作： ProGAN<br>参考解读：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/a312863063/article/details/88795147">《其中子链接值得一看》</a>（包括源码解析啥的）（甚至还有GAN的笔记）</li>
<li><a target="_blank" rel="noopener" href="http://www.gwylab.com/pdf/Note_StyleGAN.pdf">《StyleGan源码解析和拓展应用》</a></li>
<li><a target="_blank" rel="noopener" href="https://cuijiahua.com/blog/2020/07/dl-22.html">《秃头生成器1》</a><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1658228">《秃头生成器2》 </a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/swlh/hairstyle-transfer-semantic-editing-gan-latent-code-b3a6ccf91e82">NO.3</a></li>
</ul>
<p>Contribution（Problem）：</p>
<ol>
<li>解纠缠：Mapping Network</li>
<li>Noise Generator</li>
<li>AdaIN before all conv</li>
</ol>
<h2 id="Structure："><a href="#Structure：" class="headerlink" title="Structure："></a>Structure：</h2><p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930135941.png" alt="image-20210930135938114"></p>
<p><img src="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930161259.png" alt="image-20210930161258031"></p>
<h3 id="Part1：AdaIN"><a href="#Part1：AdaIN" class="headerlink" title="Part1：AdaIN"></a>Part1：AdaIN</h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/GAN/">GAN </a></div><a class="article-more button is-small is-size-7" href="/cn/StyleGAN/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/YOLOv4/"><img class="fill" src="/img/header_img/lml_bg33.jpg" alt="YOLOv4"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/YOLOv4/"><i class="fas fa-angle-double-right"></i>YOLOv4</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-10-03T05:16:40.000Z" title="2021-10-03T05:16:40.000Z">2021-10-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">11 minutes read (About 1638 words)</span></div></div><div class="content"><p>@AikenHong 20200726</p>
<p>基于YOLO v4 掌握一些CV方面训练的<strong>Trick</strong>，同时针对Typora的使用进行一个熟悉掌握。<a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">GITHUB CODE</a></p>
<p>一些相关的参考资料</p>
<p>⚡️<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/150127712">https://zhuanlan.zhihu.com/p/150127712</a></p>
<p>⚡ <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650785604&amp;idx=1&amp;sn=46bd186e5291deded9f6ec1ae6a22649&amp;chksm=871a033ab06d8a2cff370a06e9e88f578a6c16a70231778ae2f997a8b30e347c6e746db10759&amp;mpshare=1&amp;scene=1&amp;srcid=0429kHitmMCPeF2JGN1XCzik&amp;sharer_sharetime=1588144165276&amp;sharer_shareid=484a4a951d2ad320314b6b56ee9a0ba8&amp;key=c53866ae67b2b8c4b46c89671357025dcdb6b895d1ebde603135230e484682a3552d924bf6126ecf72cb98361e1171f0f0381bee5bd456520dd201034c33ec48272d62ae73345cc914c2db9c6e943a10&amp;ascene=1&amp;uin=NTkyNDg4NjQw&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=ASfZUAGjes1A%2BJpXS1yNmT0%3D&amp;pass_ticket=GB56ClnZIrs5ENfLSAh4yF9tj54n041FM39bTg38LQuW%2FKDyBPyfqKLD8SDIZgE%2F">机器之心YOLOv4</a></p>
<p>⚡️<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/390191723/answer/1177584901">https://www.zhihu.com/question/390191723/answer/1177584901</a></p>
<p><strong>本文中一些其他的收获</strong></p>
<p>•  其他可替代的Object Detection的SOTA算法有哪些</p>
<p>•  BoS，BoF方法</p>
<p>•  简直是一个Tricks的综述</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些<strong>通用的**</strong>Trick<strong>**的组合</strong>尝试，包括</p>
<p>•  加权残差连接（WRC）</p>
<p>•  Cross-Stage-Partial-connection，CSP</p>
<p>•  Cross mini-Batch Normalization，CmBN</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/YOLOv4/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/OW-OD/"><img class="fill" src="/img/header_img/lml_bg16.jpg" alt="OW Object Detector"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/OW-OD/"><i class="fas fa-angle-double-right"></i>OW Object Detector</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-28T05:44:20.000Z" title="2021-09-28T05:44:20.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-31T00:18:24.865Z" title="2023/10/31 08:18:24">2023-10-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 875 words)</span></div></div><div class="content"><p>@Aiken 2021 </p>
<p>框架撞车系列，主要看看这一篇论文中怎么解决如下的问题👇，并从中借鉴和优化的我框架设计</p>
<h2 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><strong>模型实现的主要的两个TASK：</strong></p>
<ol>
<li>Open Set Learning ： 在没有明确监督的时候，将尚未引入的目标类别识别为未知</li>
<li>Incremental Learning：类别增量学习</li>
</ol>
<p><strong>实现这两个问题的主要思路：</strong></p>
<ul>
<li><strong>自动标注</strong>：借鉴RPN的class-agnostic，以及检测和分类的显著性指标的差异，找到并自动标注NewClass</li>
<li><strong>对比聚类：</strong>使用prototype feature来进行聚类，同时计算Distance损失<br>it seems like contain a unknown prototype.</li>
<li><strong>energy based：</strong>亥姆霍兹自由能公式？</li>
</ul>
<p><img src="https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210412171723896.png" alt="image-20210412171723896"></p>
<h3 id="ENERGY-BASED"><a href="#ENERGY-BASED" class="headerlink" title="ENERGY BASED"></a><strong>ENERGY BASED</strong></h3></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV, </a><a class="link-muted" rel="tag" href="/tags/Open-World-Learning/">Open World Learning </a></div><a class="article-more button is-small is-size-7" href="/cn/OW-OD/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Attention/"><img class="fill" src="/img/header_img/lml_bg5.jpg" alt="Attention Mechanism"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Attention/"><i class="fas fa-angle-double-right"></i>Attention Mechanism</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-27T21:34:22.000Z" title="2021-09-27T21:34:22.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">18 minutes read (About 2748 words)</span></div></div><div class="content"><p>@Aiken 2020.9.16</p>
<p>对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。</p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Attention/">Attention </a></div><a class="article-more button is-small is-size-7" href="/cn/Attention/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/EfficientNet/"><img class="fill" src="/img/header_img/lml_bg15.jpg" alt="EfficientNet"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/EfficientNet/"><i class="fas fa-angle-double-right"></i>EfficientNet</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-09-27T21:34:22.000Z" title="2021-09-27T21:34:22.000Z">2021-09-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">5 minutes read (About 685 words)</span></div></div><div class="content"><p>Tags: Paper<br>URL1: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.11946.pdf">https://arxiv.org/pdf/1905.11946.pdf</a><br>URL2: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.00298.pdf">https://arxiv.org/pdf/2104.00298.pdf</a></p>
<p>提出了一种模型缩放策略，如何更高效的平衡网络的深度、宽度、和图片分辨率<br>**1. Efficient Net: Rethinking Model Scaling for Convolutional Neural Networks</p>
<ol>
<li>EfficientNetV2: Smaller Models and Faster Training**</li>
</ol>
<hr>
<p>@Aiken H 2021 find detail to code his </p>
<h1 id="Efficient-Net-V1"><a href="#Efficient-Net-V1" class="headerlink" title="Efficient Net V1"></a>Efficient Net V1</h1><p>除了提出了缩放策略以外，还使用神经架构搜索还建立了一个新的baseline network，得到了一系列模型。</p>
<p>平衡网络宽度、深度、分辨率至关重要，这种平衡可以通过简单的恒定比率缩放维度来实现，于是我们<strong>提出了一种简单有效的复合缩放</strong>方法。</p>
<p><img src="https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210610180603496.png" alt="https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210610180603496.png"></p>
<p>复合缩放的物理意义：输入图像更大的话就需要更多层来增加感受野和更多通道，从而能在更大的图像上捕获更多细粒度的图案，而宽度和深度（对于表达能力来说很重要）之间也存在着一定的关系，“我们”是第一个对此进行了建模的。</p>
<p>从各个维度单独的进行缩放能发现都存在着增益瓶颈，如何去得到这么一个合适的等比缩放增益<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/EfficientNet/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/RL-DouZero/"><img class="fill" src="/img/header_img/lml_bg23.jpg" alt="RL-DouZero"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/RL-DouZero/"><i class="fas fa-angle-double-right"></i>RL-DouZero</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-07-06T05:51:48.000Z" title="2021-07-06T05:51:48.000Z">2021-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">9 minutes read (About 1337 words)</span></div></div><div class="content"><p>Desc: GAME, RL<br>Finished?: Yes<br>Tags: Paper<br>URL1: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.06135">https://arxiv.org/abs/2106.06135</a><br>URL2: <a target="_blank" rel="noopener" href="https://github.com/kwai/DouZero">https://github.com/kwai/DouZero</a><br>URL3: <a target="_blank" rel="noopener" href="https://github.com/datamllab/rlcard-showdown）">https://github.com/datamllab/rlcard-showdown）</a></p>
<p>使用蒙特卡洛方法进行自我对弈不断更新预测模型的方法，这实际上也是普通人对于强化学习如何在self-play中实现自我更新的最基础的想法把：<br>自我对弈（记录动作序列）- 用最终的胜负（价值）更新网络。</p>
<h2 id="算法的设计和思路"><a href="#算法的设计和思路" class="headerlink" title="算法的设计和思路"></a>算法的设计和思路</h2><p>算法的目标是学习一个价值网路。网络的输入是当前状态和一个动作，输出是在当前状态做这个动作的期望收益（比如胜率）。简单来说，价值网络在每一步计算出哪种牌型赢的概率最大，然后选择最有可能赢的牌型。蒙特卡罗方法不断重复以下步骤来优化价值网络：</p>
<ul>
<li>用价值网络生成一场对局</li>
<li>记录下该对局中所有的状态、动作和最后的收益（胜率）</li>
<li>将每一对状态和动作作为网络输入，收益作为网络输出，用梯度下降对价值网络进行一次更新</li>
</ul>
<p>其实，所谓的蒙特卡罗方法就是一种随机模拟，即通过不断的重复实验来估计真实价值。</p>
<p>如下图所示，斗零采用一个价值神经网络，其输入是状态和动作，输出是价值。首先，过去的出牌用 LSTM 神经网络进行编码。然后 LSTM 的输出以及其他的表征被送入了 6 层全连接网络，最后输出价值。<br></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Reinforcement-learning/">Reinforcement learning </a></div><a class="article-more button is-small is-size-7" href="/cn/RL-DouZero/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/Pooling/"><img class="fill" src="/img/header_img/lml_bg14.jpg" alt="Pooling"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/Pooling/"><i class="fas fa-angle-double-right"></i>Pooling</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-06-23T05:48:56.000Z" title="2021-06-23T05:48:56.000Z">2021-06-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">17 minutes read (About 2493 words)</span></div></div><div class="content"><h1 id="DownSampling：Pooling的全面调研"><a href="#DownSampling：Pooling的全面调研" class="headerlink" title="DownSampling：Pooling的全面调研"></a>DownSampling：Pooling的全面调研</h1><p>@Aiken 2021 笔记摘录：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341820742">深度神经网络中的池化方法：全面调研（1989-2020） - 知乎</a> ；<a target="_blank" rel="noopener" href="https://www.sohu.com/a/442710521_823210">相同论文的简单中文Version</a></p>
<p>16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…</p>
<p>来自 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341820742">https://zhuanlan.zhihu.com/p/341820742</a></p>
<p>原文：《Pooling Methods in Deep Neural Networks, a Review》</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112216409">整合2</a></p>
<h2 id="池化的根本目的（Motivation）"><a href="#池化的根本目的（Motivation）" class="headerlink" title="池化的根本目的（Motivation）"></a>池化的根本目的（Motivation）</h2><p>卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。</p>
<p>池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层<strong>极大地减小了输入的空间尺寸</strong>。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。</p>
<ul>
<li>池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。</li>
<li>增大感受野；</li>
<li>降低优化难度和参数数目，</li>
</ul>
<p>理想的池化方法应仅提取有用的信息，并丢弃无关的细节。</p>
<p><strong>特征不变性、特征降维、在一定程度上防止过拟合，更方便优化</strong></p></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Survey/">Survey, </a><a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/Pooling/">Pooling </a></div><a class="article-more button is-small is-size-7" href="/cn/Pooling/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/cn/OW-openmix/"><img class="fill" src="/img/header_img/lml_bg36.jpg" alt="OW-openmix"></a></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/cn/OW-openmix/"><i class="fas fa-angle-double-right"></i>OW-openmix</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2021-06-23T05:45:50.000Z" title="2021-06-23T05:45:50.000Z">2021-06-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-30T09:27:38.000Z" title="2023/10/30 17:27:38">2023-10-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">6 minutes read (About 836 words)</span></div></div><div class="content"><p>@Aiken 2021 究极万恶的撞车论文</p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><strong>Motivation</strong> ：Tackle the problem of 发现无标注数据中与给定（已知）类别不相交的新类。</p>
<p><strong>Related Research：</strong></p>
<p>现有的方法通常1. 使用标记数据对模型进行预训练； 2. 无监督聚类在未标记的数据中识别新的类</p>
<blockquote>
<p>作者认为label带来的essential knowledge在第二步中没有被充分学习利用到，这样模型就只能从第一步的现成知识中获益，而不能利用标记数据和未标记数据之间的潜在关系</p>
</blockquote></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div><a class="article-more button is-small is-size-7" href="/cn/OW-openmix/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/tags/Machine-Learning/page/0/">Previous</a></div><div class="pagination-next"><a href="/tags/Machine-Learning/page/2/"> common.next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/tags/Machine-Learning/">1</a></li><li><a class="pagination-link" href="/tags/Machine-Learning/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/title.jpg" alt="AikenH"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">AikenH</p><p class="is-size-6 is-block">Future Full-Stack Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ShenZhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">137</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">102</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/AikenH" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="ZhiHu" href="https://www.zhihu.com/people/Aiken-h"><i class="fab fa-zhihu"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/1788200627"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Steam" href="https://steamcommunity.com/id/AikenH/"><i class="fab fa-steam"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/AikenH"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/cn/BackupToolsForHomeServer/"><img src="/img/header_img/lml_bg1.jpg" alt="家庭服务器的备份工具选择"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-12-29T00:04:06.000Z">2023-12-29</time></p><p class="title"><a href="/cn/BackupToolsForHomeServer/">家庭服务器的备份工具选择</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/%E5%AE%B6%E5%BA%AD%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B4%E4%BD%93%E6%96%B9%E6%A1%88/"><img src="/img/header_img/lml_bg1.jpg" alt="家庭服务器整体方案"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-12-20T00:24:36.000Z">2023-12-20</time></p><p class="title"><a href="/cn/%E5%AE%B6%E5%BA%AD%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B4%E4%BD%93%E6%96%B9%E6%A1%88/">家庭服务器整体方案</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/StableDiffusionWebUI%E9%89%B4%E6%9D%83%E8%AE%BE%E8%AE%A1/"><img src="/img/header_img/lml_bg1.jpg" alt="StableDiffusionWebUI鉴权设计"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-12-08T07:42:36.000Z">2023-12-08</time></p><p class="title"><a href="/cn/StableDiffusionWebUI%E9%89%B4%E6%9D%83%E8%AE%BE%E8%AE%A1/">StableDiffusionWebUI鉴权设计</a></p><p class="categories"><a href="/categories/Machine-Learning/">Machine Learning</a> / <a href="/categories/Machine-Learning/AIGC/">AIGC</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%B6%E5%BA%AD%E5%BD%B1%E9%9F%B3%E4%B8%AD%E5%BF%832/"><img src="/img/header_img/lml_bg1.jpg" alt="树莓派家庭影音中心2"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-11T04:08:37.000Z">2023-11-11</time></p><p class="title"><a href="/cn/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%B6%E5%BA%AD%E5%BD%B1%E9%9F%B3%E4%B8%AD%E5%BF%832/">树莓派家庭影音中心2</a></p><p class="categories"><a href="/categories/Dev/">Dev</a> / <a href="/categories/Dev/Raspberry-pie/">Raspberry-pie</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/cn/emby_localhost_crack_by_nginx/"><img src="/img/header_img/lml_bg2.jpg" alt="破解本地自托管Emby服务"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-11-10T06:05:15.000Z">2023-11-10</time></p><p class="title"><a href="/cn/emby_localhost_crack_by_nginx/">破解本地自托管Emby服务</a></p><p class="categories"><a href="/categories/NAS/">NAS</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Acceleration/"><span class="tag">Acceleration</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention/"><span class="tag">Attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Augmentation/"><span class="tag">Augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Blog/"><span class="tag">Blog</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Clash/"><span class="tag">Clash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud/"><span class="tag">Cloud</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Colab/"><span class="tag">Colab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Configuration/"><span class="tag">Configuration</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cpp/"><span class="tag">Cpp</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Database/"><span class="tag">Database</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataset/"><span class="tag">Dataset</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dev/"><span class="tag">Dev</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Django/"><span class="tag">Django</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Draft/"><span class="tag">Draft</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DualSystem/"><span class="tag">DualSystem</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Env/"><span class="tag">Env</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Game-Generate/"><span class="level-start"><span class="level-item">Game Generate</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Leetcode/"><span class="level-start"><span class="level-item">Leetcode</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Blog/"><span class="level-start"><span class="level-item">Blog</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Blog/Gitbook/"><span class="level-start"><span class="level-item">Gitbook</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Blog/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Dev/"><span class="level-start"><span class="level-item">Dev</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/Dev/Devops/"><span class="level-start"><span class="level-item">Devops</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/Raspberry-pie/"><span class="level-start"><span class="level-item">Raspberry-pie</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Dev/SSH/"><span class="level-start"><span class="level-item">SSH</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Docker/Containers/"><span class="level-start"><span class="level-item">Containers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Editor/Obsidian/"><span class="level-start"><span class="level-item">Obsidian</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Editor/Vim/"><span class="level-start"><span class="level-item">Vim</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Editor/Vscode/"><span class="level-start"><span class="level-item">Vscode</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Frontend/"><span class="level-start"><span class="level-item">Frontend</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Frontend/Vue/"><span class="level-start"><span class="level-item">Vue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Github/"><span class="level-start"><span class="level-item">Github</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/"><span class="level-start"><span class="level-item">Langs</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Langs/Bash/"><span class="level-start"><span class="level-item">Bash</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Cpp/"><span class="level-start"><span class="level-item">Cpp</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Markdown/"><span class="level-start"><span class="level-item">Markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Nodejs/"><span class="level-start"><span class="level-item">Nodejs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Langs/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/CLI/"><span class="level-start"><span class="level-item">CLI</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MacOS/"><span class="level-start"><span class="level-item">MacOS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">49</span></span></a><ul><li><a class="level is-mobile" href="/categories/Machine-Learning/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/Dataset/"><span class="level-start"><span class="level-item">Dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/NAS/"><span class="level-start"><span class="level-item">NAS</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/NAS/NAT/"><span class="level-start"><span class="level-item">NAT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Photography/"><span class="level-start"><span class="level-item">Photography</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Windows/APPs/"><span class="level-start"><span class="level-item">APPs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/Dual-System/"><span class="level-start"><span class="level-item">Dual System</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/Powershell/"><span class="level-start"><span class="level-item">Powershell</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows/WSL2/"><span class="level-start"><span class="level-item">WSL2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Aiken&#039;s Blog</a><p class="is-size-7"><span>&copy; 2024 AikenH</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_pv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span> and <span id="busuanzi_container2_site_uv"><span id="busuanzi_value_site_pv">0</span>&nbsp;visits</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>